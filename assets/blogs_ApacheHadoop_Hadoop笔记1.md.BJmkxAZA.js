import{_ as i,c as a,o as n,ak as p}from"./chunks/framework.CmzJUe0_.js";const l="/assets/hadoop_20240701173106.D5hIoduX.png",h="/assets/hadoop_20240702165036.Bc7f9V0M.png",t="/assets/hadoop_20240709164126.BoJ0Mfv0.png",k="/assets/hadoop_20240703161546.Jde1ZdqQ.png",e="/assets/hadoop_20240704093254.XP8BH5cE.png",d="/assets/hadoop_20240704102116.CsVrpseg.png",o="/assets/hadoop_20240704170512.D9N8LRxd.png",r="/assets/hadoop_20240705092922.C2mLiBCs.png",E="/assets/hadoop_20240705104632.D2FbmD3W.png",g="/assets/hadoop_20240705174750.bxQqPsfu.png",y="/assets/hadoop_20240710155943.Cc6nOkJz.png",c="/assets/hadoop_20240710164433.Bi1575jT.png",v=JSON.parse('{"title":"Hadoop笔记1","description":"","frontmatter":{"title":"Hadoop笔记1","date":"2024-07-01T00:00:00.000Z","sidebar":"auto","categories":["大数据"],"tags":["Hadoop"]},"headers":[],"relativePath":"blogs/ApacheHadoop/Hadoop笔记1.md","filePath":"blogs/ApacheHadoop/Hadoop笔记1.md"}'),F={name:"blogs/ApacheHadoop/Hadoop笔记1.md"};function u(A,s,D,C,B,b){return n(),a("div",null,s[0]||(s[0]=[p('<p>[toc]</p><h1 id="hadoop笔记1" tabindex="-1">Hadoop笔记1 <a class="header-anchor" href="#hadoop笔记1" aria-label="Permalink to &quot;Hadoop笔记1&quot;">​</a></h1><p>当前使用版本为： hadoop-3.3.6</p><h2 id="大数据介绍" tabindex="-1">大数据介绍 <a class="header-anchor" href="#大数据介绍" aria-label="Permalink to &quot;大数据介绍&quot;">​</a></h2><p>狭义上：大数据是指一类技术栈，用来对海量数据进行处理的软件技术体系。 广义上：大数据是指数字化时代，信息化时代的基础数据支撑，用数据为生活赋能。</p><blockquote><p>大数据的核心工作是什么？</p></blockquote><ul><li>数据存储：可以存储海量待处理数据。</li><li>数据计算：可以从海量数据中计算挖掘出有价值的数据结果。</li><li>数据传输：可以将海量数据传输给各个目标。</li></ul><blockquote><p>大数据软件技术生态有哪些？</p></blockquote><p>由于大数据的核心工作分别是: 数据存储，数据计算，数据传输。</p><p>对于数据存储方面：</p><ul><li>Apache Hadoop框架的HDFS组件是大数据技术体系中使用最广泛的分布式存储技术。</li><li>Apache HBase是大数据技术体系中使用最广泛的NoSQL，K-V键值对数据库技术。HBase是在HDFS的基础上构建的。</li><li>Apache KUDU 也是大数据技术系统中使用较多的分布式存储引擎。</li><li>除此之外，还有各个云平台提供的大数据存储服务。例如阿里云的OSS,亚马逊的S3云存储等都可以替代。</li></ul><p>对于数据计算方面：</p><ul><li>Apache Hadoop框架的MapReduce组件是最早的大数据分布式计算引擎。</li><li>Apache Hive 框架是一款以SQL为开发语言的分布式计算框架。其底层使用了Hadoop框架的MapReduce组件技术。</li><li>Apache Spark 是目前全球内最火热的分布式内存计算引擎技术。</li><li>Apache Flink 同样也是一款大数据分布式内存计算引擎，主要在实时计算（流计算）领域，Flink占据主流。</li></ul><p>对于数据传输方面：</p><ul><li>Apache Kafka 是一款分布式消息系统，可以完成海量数据的数据传输工作。</li><li>Apache Pulsar 同样也是一款分布式的消息系统。</li><li>Apache Flume 是一款流式数据采集工具，可以从非常多的数据源中进行数据采集。</li><li>..............</li></ul><h2 id="hadoop介绍" tabindex="-1">Hadoop介绍 <a class="header-anchor" href="#hadoop介绍" aria-label="Permalink to &quot;Hadoop介绍&quot;">​</a></h2><p>Hadoop的全称是Apache Hadoop。</p><p>当前使用版本为： hadoop-3.3.6</p><p>Hadoop是Apache软件基金会下的顶级开源项目。Hadoop的主要功能如下。</p><ul><li>分布式数据存储</li><li>分布式数据计算</li><li>分布式资源调度</li></ul><p>总结：Hadoop是一个开源的分布式软件框架。提供分布式存储，计算，资源调度的解决方案。开发者可以通过Hadoop来实现海量数据的存储和计算。</p><blockquote><p>Hadoop内部存在三大组件，分别是：</p></blockquote><ul><li>HDFS组件： HDFS是Hadoop内部的分布式存储组件。可以用来构建分布式文件系统，存储海量数据。</li><li>MapReduce组件：MapReduce是Hadoop内部的分布式计算组件，提供接口给用户进行分布式计算。</li><li>YARN组件: YARN是Hadoop内部的分布式资源调度组件。可以帮助用户实现大规模集群的资源调度。</li></ul><p><img src="'+l+'" alt="hadoop_20240701173106.png"></p><h3 id="hdfs分布式文件系统-介绍" tabindex="-1">HDFS分布式文件系统-介绍 <a class="header-anchor" href="#hdfs分布式文件系统-介绍" aria-label="Permalink to &quot;HDFS分布式文件系统-介绍&quot;">​</a></h3><p>HDFS 分布式文件系统 是 Hadoop 的三大组件之一。</p><ul><li>HDFS 全称是 Hadoop Distribued File System (Hadoop 分布式文件系统)</li><li>HDFS 是 Hadoop内部的分布式数据存储解决方案。</li><li>HDFS 可以在多台服务器上进行集群部署，并且存储海量的数据。</li></ul><blockquote><p>为什么需要分布式文件存储？</p></blockquote><p>由于单个服务器的数据存储能力是有上限的，因此当数据量大到一定程度的时候，需要多台服务器一起存储数据才行。</p><blockquote><p>HDFS的集群架构</p></blockquote><p>HDFS的集群架构是主从模式的，即有一个主节点，多个从节点，共同组成的集群。</p><p>在HDFS的集群架构中，主要有三种不同的角色。</p><ul><li>主角色 NameNode ：主角色是一个独立进程。主要负责管理整个HDFS系统，管理DataNode从角色。</li><li>从角色 DataNode ：从角色也是一个独立进程。主要负责数据存储。</li><li>辅助角色 SecondaryNameNode ：辅助角色也是一个独立进程。主要负责辅助主角色，帮助主角色完成元数据整理工作。</li></ul><p>HDFS的集群架构如下图所示 <img src="'+h+'" alt="hadoop_20240702165036.png"></p><h3 id="mapreduce分布式计算-介绍" tabindex="-1">MapReduce分布式计算-介绍 <a class="header-anchor" href="#mapreduce分布式计算-介绍" aria-label="Permalink to &quot;MapReduce分布式计算-介绍&quot;">​</a></h3><blockquote><p>什么是分布式计算？</p></blockquote><p>分布式计算是指通过多台服务器协同工作，共同完成一个计算任务。从而得到计算结果。</p><p>分布式计算的2种工作模式：</p><ol><li>分散汇总模式。（Hadoop的MapReduce使用的就是这种模式）</li><li>中心调度，步骤执行模式。（Spark,Flink框架使用这种模式）</li></ol><blockquote><p>什么是MapReduce？</p></blockquote><p>MapReduce使用的是分散汇总模式的分布式计算框架。也是Hadoop内部的分布式计算的组件。</p><p>MapReduce框架内部提供了两大接口。</p><ul><li>Map分散接口，由服务器对数据进行分布式处理。</li><li>Reduce聚合接口，将分布式的处理结果进行汇总统计。</li></ul><p style="color:red;"> 注意：MapReduce提供了Map分散接口和Reduce聚合接口，给开发者使用。但是由于年代久远，MapReduce框架的代码，性能已经过时了。 </p><p style="color:red;"> 因此，现在主要使用Apache Hive框架来进行分布式计算。Apache Hive框架底层使用的就是MapReduce框架，所以我们只需对MapReduce框架简单了解即可。 </p><blockquote><p>MapReduce的运行机制</p></blockquote><ol><li>MapReduce会将一个计算任务，分解成多个小的Map Task（分散任务） 和 Reduce Task（聚合任务）。</li><li>然后将Map Task（分散任务） 和 Reduce Task（聚合任务）分配到对应的服务器中去进行计算。</li><li>最后将多个服务器中的计算结果通过Reduce Task（聚合任务）聚合到一起。从而得到这个计算任务的计算结果。</li></ol><h3 id="yarn分布式资源调度-介绍" tabindex="-1">YARN分布式资源调度-介绍 <a class="header-anchor" href="#yarn分布式资源调度-介绍" aria-label="Permalink to &quot;YARN分布式资源调度-介绍&quot;">​</a></h3><blockquote><p>什么是分布式资源调度？</p></blockquote><p>资源通常是指服务器的硬件资源。例如CPU，内存，硬盘，网络等。资源调度的目的是最大化的利用服务器的硬件资源。</p><p>分布式资源调度是指管理整个分布式服务器集群的全部资源，并进行统一调度。</p><blockquote><p>什么是YARN?</p></blockquote><p>YARN是Hadoop内部的分布式资源调度组件，可以将Hadoop的资源统一管理，并进行分配。</p><blockquote><p>MapReduce 和 YARN 的关系？</p></blockquote><p>YARN 统一分配资源给MapReduce使用，而MapReduce需要这些资源才能进行分布式计算。</p><blockquote><p>YARN的集群架构</p></blockquote><p>YARN的集群架构是主从模式的，即有一个主节点，多个从节点，共同组成的集群。</p><p>在YARN的集群架构中，主要有2种不同的角色。</p><ul><li>主角色 ResourceManager ：主角色负责整个集群的资源调度，协调各个从角色所需要的资源。</li><li>从角色 NodeManager ：从角色主要负责调度的单个服务器上的资源给程序使用。</li></ul><p>YARN的集群架构如下图所示 <img src="'+t+'" alt="hadoop_20240709164126.png"></p><h2 id="hadoop的安装和部署" tabindex="-1">Hadoop的安装和部署 <a class="header-anchor" href="#hadoop的安装和部署" aria-label="Permalink to &quot;Hadoop的安装和部署&quot;">​</a></h2><p>下面是在docker环境中安装和部署Hadoop的。</p><p>由于目前dockerhub中的Hadoop镜像都是旧的镜像格式，最新版本的docker无法下载该镜像。</p><p>当尝试下载官方的Hadoop镜像时，会提示该Hadoop镜像是旧的镜像格式，不建议下载使用。 <img src="'+k+`" alt="hadoop_20240703161546.png"></p><p>因此下面的笔记是先在centos镜像的基础上安装部署java和hadoop。从而构建出Hadoop镜像。</p><h3 id="_1-构建hadoop镜像" tabindex="-1">1.构建Hadoop镜像 <a class="header-anchor" href="#_1-构建hadoop镜像" aria-label="Permalink to &quot;1.构建Hadoop镜像&quot;">​</a></h3><ol><li>先下载centos镜像</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> pull</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> centos:7</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> images</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> #查看镜像</span></span></code></pre></div><ol start="2"><li>构建Hadoop镜像</li></ol><p>在centos镜像的基础上安装SSH服务,java，hadoop。然后通过Dockerfile构建出一个新镜像。</p><p>步骤1：创建Dockerfile文件。该文件名称就是Dockerfile，注意该文件没有后缀名。</p><p>步骤2：编辑Dockerfile文件。内容如下所示。</p><p>注意：在Dockerfile所在目录下提前准备好 jdk-8u202-linux-x64.tar.gz 与 hadoop-3.3.6.tar.gz 安装包。当然你也可以准备其他版本的安装包。</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># FROM:基于什么镜像来制作自己的镜像</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">FROM</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> centos:7</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># MAINTAINER:表示该镜像的作者（维护者）</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">MAINTAINER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> shuyx</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置yum源，包括修改仓库地址、提速、更新</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> cd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/yum.repos.d/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sed</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;s/mirrorlist/#mirrorlist/g&#39;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/yum.repos.d/CentOS-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">*</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sed</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;s|#baseurl=http://mirror.centos.org|baseurl=http://mirrors.aliyun.com|g&#39;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/yum.repos.d/CentOS-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">*</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> makecache</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> update</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 安装ssh服务和ssh客户端。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> openssh-server</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sudo</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sed</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;s/UsePAM yes/UsePAM no/g&#39;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/ssh/sshd_config</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> openssh-clients</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 生成ssh密钥，注意此处设置了root用户的密码为root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> echo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;root:root&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> chpasswd</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> echo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;root   ALL=(ALL)       ALL&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> &gt;&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/sudoers</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ssh-keygen</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> dsa</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/ssh/ssh_host_dsa_key</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ssh-keygen</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> rsa</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/ssh/ssh_host_rsa_key</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 开启ssh服务，暴露SSH的默认端口22。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> mkdir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /var/run/sshd</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">EXPOSE</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 22</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">CMD</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;/usr/sbin/sshd&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;-D&quot;]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将本地的jdk安装包，复制到容器的/usr/local/目录中。并进行解压，配置环境变量</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ADD</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> jdk-8u202-linux-x64.tar.gz</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> mv</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/jdk1.8.0_202</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> JAVA_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> PATH</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> $JAVA_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/bin:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将本地的hadoop安装包，复制到容器的/usr/local/目录中。并进行解压，配置环境变量</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ADD</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop-3.3.6.tar.gz</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> mv</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop-3.3.6</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HADOOP_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> PATH</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> $HADOOP_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/bin:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> PATH</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> $HADOOP_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/sbin:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定root用户访问</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_NAMENODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_DATANODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_SECONDARYNAMENODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> YARN_RESOURCEMANAGER_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> YARN_NODEMANAGER_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 安装 which,sudo,vim 命令行工具</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> which</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vim</span></span></code></pre></div><p>步骤3：在Dockerfile文件的同目录中，使用下面的命令，创建新镜像my-hadoop-image</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># &quot;.&quot;表示当前目录，即Dockerfile所在的位置</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># my-hadoop-image 为新镜像的名称</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> build</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-image</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> .</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询新镜像my-hadoop-image</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> images</span></span></code></pre></div><h3 id="_2-部署hadoop容器" tabindex="-1">2.部署Hadoop容器 <a class="header-anchor" href="#_2-部署hadoop容器" aria-label="Permalink to &quot;2.部署Hadoop容器&quot;">​</a></h3><ol><li>先创建一个docker网络。这样能很方便的让多个Hadoop容器之间互相通信。</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建一个docker网络</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> create</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-net</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询网络</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ls</span></span></code></pre></div><ol start="2"><li>创建多个Hadoop容器</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建hadoop01容器</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -itd</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-net</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --name</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop01</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 50070:50070</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 38088:8088</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-image</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建hadoop02容器</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -itd</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-net</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --name</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-image</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建hadoop03容器</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -itd</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-net</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --name</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-image</span></span></code></pre></div><p>50070和8088端口，主要是用来在浏览器中访问hadoop WEB界面的。</p><ol start="3"><li>测试容器内的java，hadoop是否安装成功</li></ol><p>在每一个容器终端中执行下面命令</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询安装的java,hadoop版本</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">java</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -version</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> version</span></span></code></pre></div><p>安装结果如下图所示 <img src="`+e+'" alt="hadoop_20240704093254.png"></p><ol start="4"><li>hadoop安装包中的目录结构</li></ol><p><img src="'+d+`" alt="hadoop_20240704102116.png"></p><h3 id="hadoop服务授权给普通用户-可选" tabindex="-1">Hadoop服务授权给普通用户（可选） <a class="header-anchor" href="#hadoop服务授权给普通用户-可选" aria-label="Permalink to &quot;Hadoop服务授权给普通用户（可选）&quot;">​</a></h3><p>通常在测试环境中，我们可以使用root用户来操作 Hadoop 中的服务组件。但是在生产环境中，强烈建议避免以 root 用户身份直接操作 Hadoop 的组件，这有助于减少安全风险。</p><p>因此为了确保数据安全，生产环境中的hadoop系统不以root用户启动。我们可以创建普通用户hadoop，并且以普通用户hadoop来操作整个hadoop服务。</p><blockquote><p>在Hadoop容器中创建普通用户hadoop</p></blockquote><p>在每一个Hadoop容器终端中,执行下面几条命令</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建普通用户hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">useradd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置hadoop用户的密码为123456</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">passwd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将当前用户从root用户切换到hadoop用户</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">su</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> -</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span></code></pre></div><blockquote><p>Hadoop容器中的hadoop相关目录文件授权给普通用户hadoop</p></blockquote><p>我们需要把Hadoop容器中的hadoop相关目录授权给之前创建的普通用户hadoop</p><p>在每一个Hadoop容器终端中,执行下面命令。注意需要用root用户来执行该命令</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 先切换到root用户，该命令需要输入root用户的密码root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">su</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> -</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 执行授权命令</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">chown</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -R</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop:hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span></span></code></pre></div><blockquote><p>如果想要普通用户hadoop，也能有权限使用hadoop的服务。</p></blockquote><p>方式1： 在构建hadoop镜像的时候，将下面环境变量设定为hadoop用户访问</p><p>在Dockerfile文件中编辑下面内容。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定 hadoop 用户访问</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_NAMENODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_DATANODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_SECONDARYNAMENODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> YARN_RESOURCEMANAGER_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> YARN_NODEMANAGER_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span></code></pre></div><p>方式2：在每一个hadoop容器中，进行环境变量的配置。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 编辑环境变量文件</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">vim</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/profile</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop用户访问</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HDFS_NAMENODE_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HDFS_DATANODE_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HDFS_SECONDARYNAMENODE_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> YARN_RESOURCEMANAGER_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> YARN_NODEMANAGER_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span></code></pre></div><h3 id="_3-hadoop容器之间互相配置ssh免密登录" tabindex="-1">3.Hadoop容器之间互相配置SSH免密登录 <a class="header-anchor" href="#_3-hadoop容器之间互相配置ssh免密登录" aria-label="Permalink to &quot;3.Hadoop容器之间互相配置SSH免密登录&quot;">​</a></h3><p>在每个Hadoop容器中，配置免密码互相SSH登录。方便多个Hadoop容器之间互相登录访问。也方便多个Hadoop容器之间互相传输文件。</p><ol><li>在每一个Hadoop容器终端中,执行下面几条命令</li></ol><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 先生成SSH密钥，一路回车即可</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh-keygen</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> rsa</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -b</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 4096</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置SSH免密登录。注意 hadoop01,hadoop02,hadoop03 是各个hadoop容器的名称。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 该命令会让你输入root用户的密码。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh-copy-id</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop01</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh-copy-id</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh-copy-id</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03</span></span></code></pre></div><p>由于多个hadoop容器在同一个网络中，因此hadoop容器互相可以通过容器名称找到其他hadoop容器。</p><ol start="2"><li>执行命令完毕后，hadoop01,hadoop02,hadoop03 三个容器之间就可以完成root用户之间的免密登录。</li><li>在Hadoop容器终端中进行测试</li></ol><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过ssh登录到hadoop01容器中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop01</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过ssh登录到hadoop02容器中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过ssh登录到hadoop03容器中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03</span></span></code></pre></div><h3 id="_4-1-hadoop容器中的hdfs集群配置" tabindex="-1">4.1 Hadoop容器中的HDFS集群配置 <a class="header-anchor" href="#_4-1-hadoop容器中的hdfs集群配置" aria-label="Permalink to &quot;4.1 Hadoop容器中的HDFS集群配置&quot;">​</a></h3><p>由于HDFS分布式存储系统有三个角色，NameNode主角色，DataNode从角色，辅助角色SecondaryNameNode。</p><p>因此我们需要给每个hadoop容器去分配这些角色。分配结果如下表所示。</p><table tabindex="0"><thead><tr><th>节点容器</th><th>所分配的角色</th></tr></thead><tbody><tr><td>hadoop01 容器</td><td>NameNode主角色，DataNode从角色，辅助角色SecondaryNameNode。</td></tr><tr><td>hadoop02 容器</td><td>DataNode从角色</td></tr><tr><td>hadoop03 容器</td><td>DataNode从角色</td></tr></tbody></table><p>每个角色都相当于是一个进程或者一个节点，因此可以理解为三个Hadoop容器中存在5个进程节点。其中一个主进程节点NameNode，三个从进程节点DataNode，以及一个辅助进程节点SecondaryNameNode。</p><blockquote><p>配置方式</p></blockquote><p>HDFS集群配置需要对如下文件的修改</p><ul><li>workers 配置DataNode从角色是哪些。</li><li>hadoop-env.sh 配置hadoop的环境变量文件，需要将jdk的路径配置进去。</li><li>core-site.xml 是hadoop的核心配置，需要指定hadoop的基本配置信息。</li><li>hdfs-site.xml 是hadoop中的HDFS组件的配置文件。</li></ul><p><span style="color:red;">先配置hadoop01容器，然后将hadoop01容器中的hadoop目录整体复制到其他hadoop容器中即可。下面是在hadoop01容器中进行HDFS集群配置</span></p><blockquote><p>① 配置 workers 文件</p></blockquote><p>编辑/usr/local/hadoop/etc/hadoop/workers文件。配置三个DataNode从角色所在的hadoop容器名称。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注释默认的localhost</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># localhost</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop01</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop02</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop03</span></span></code></pre></div><p>由于三个hadoop容器都是在同一个网络my-hadoop-net下，容器可以用容器名称来找到其他hadoop容器。因此直接在workers文件中直接填写容器名称即可。</p><blockquote><p>② 配置 <code>hadoop-env.sh</code></p></blockquote><p>编辑 /usr/local/hadoop/etc/hadoop/hadoop-env.sh文件。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop使用的java环境的路径</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JAVA_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop的安装目录位置</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop配置文件的目录位置</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_CONF_DIR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop/etc/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop运行日志目录位置</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_LOG_DIR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop/logs</span></span></code></pre></div><blockquote><p>③ 配置core-site.xml</p></blockquote><p>编辑 /usr/local/hadoop/etc/hadoop/core-site.xml</p><div class="language-xml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">xml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 访问NameNode主角色的地址路径，hadoop01为NameNode主角色所在的容器名称。8020为通讯端口，端口可以随意指定，默认为8020端口 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;fs.defaultFS&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hdfs://hadoop01:8020&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!--文件缓冲区大小，为131702比特--&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;io.file.buffer.size&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;131702&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span></code></pre></div><blockquote><p>④ HDFS配置文件 hdfs-site.xml</p></blockquote><p>编辑 /usr/local/hadoop/etc/hadoop/hdfs-site.xml</p><div class="language-xml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">xml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置hdfs文件系统中，默认创建的文件权限 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.datanode.data.dir.perm&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;700&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- NameNode主角色节点中元数据存储位置 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.namenode.name.dir&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;file:/usr/local/hadoop/hdfs/namenode&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- NameNode主角色节点允许哪些DataNode从角色节点进行授权连接 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 此处填写DataNode从角色节点所在的容器名称即可 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.namenode.hosts&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01,hadoop02,hadoop03&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- DataNode从角色节点的数据存储目录 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.datanode.data.dir&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;file:/usr/local/hadoop/hdfs/datanode&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- hdfs数据块大小（以字节为单位，默认为128MB）--&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.blocksize&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;134217728&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 指定了 NameNode 提供 HTTP 服务的地址。通常用于浏览器访问 Hadoop 的管理界面 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.namenode.http-address&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01:50070&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span></code></pre></div><p>由于我们在hdfs-site.xml配置文件中，指定了namenode目录和datanode目录。因此我们还需要在NameNode主角色所在的hadoop容器中（即hadoop01容器），创建这两个目录。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">mkdir</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop/hdfs/namenode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">mkdir</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop/hdfs/datanode</span></span></code></pre></div><blockquote><p>⑤ 将hadoop01容器中的hadoop目录，复制到其他hadoop容器中</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop02容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02:/usr/local</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop03容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03:/usr/local</span></span></code></pre></div><p>scp命令需要输入root用户的密码，之前构建镜像的时候，设置了root用户密码为root。</p><p>以上关于Hadoop容器中的HDFS集群配置就完成了。</p><h3 id="_4-2-hadoop容器中的mapreduce配置" tabindex="-1">4.2 Hadoop容器中的MapReduce配置 <a class="header-anchor" href="#_4-2-hadoop容器中的mapreduce配置" aria-label="Permalink to &quot;4.2 Hadoop容器中的MapReduce配置&quot;">​</a></h3><blockquote><p>配置方式</p></blockquote><ol><li>无需启动任何进程。只需修改对应配置文件即可。</li></ol><p>先修改hadoop01主节点容器中的配置，然后复制给其他hadoop容器中。</p><blockquote><p>① 编辑mapred-env.sh文件</p></blockquote><p>在hadoop01容器中，编辑 /usr/local/hadoop/etc/hadoop/mapred-env.sh文件</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop使用的java环境的路径</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JAVA_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置JobHistoryServer进程的内存为1G</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_JOB_HISTORYSERVER_HEAPSIZE</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置日志级别为INFO</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_MAPRED_ROOT_LOGGER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">INFO,RFA</span></span></code></pre></div><blockquote><p>② 编辑mapred-site.xml文件</p></blockquote><p>在hadoop01容器中，编辑 /usr/local/hadoop/etc/hadoop/mapred-site.xml文件</p><div class="language-xml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">xml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置MapReduce的运行框架为YARN --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.framework.name&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置jobhistory进程的通信端口 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.jobhistory.address&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01:10020&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置jobhistory进程的web端口 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.jobhistory.webapp.address&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01:19888&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置jobhistory进程的信息记录的路径 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;file:/usr/local/hadoop/mr-history/tmp&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置jobhistory进程的信息记录路径 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.jobhistory.done-dir&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;file:/usr/local/hadoop/mr-history/done&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置HADOOP_MAPRED_HOME环境变量 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.app.mapreduce.am.env&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;HADOOP_MAPRED_HOME=\${HADOOP_HOME}&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置HADOOP_MAPRED_HOME环境变量 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.map.env&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;HADOOP_MAPRED_HOME=\${HADOOP_HOME}&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置HADOOP_MAPRED_HOME环境变量 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.reduce.env&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;HADOOP_MAPRED_HOME=\${HADOOP_HOME}&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span></code></pre></div><ul><li>\${HADOOP_HOME} 的值为/usr/local/hadoop。在构建Hadoop镜像的时候，就设置了该环境变量。</li></ul><blockquote><p>③ 文件转发</p></blockquote><p>将hadoop01容器中的修改好的配置文件，都复制到其他hadoop容器中。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop02容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02:/usr/local</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop03容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03:/usr/local</span></span></code></pre></div><p>以上MapReduce配置就完成了</p><h3 id="_4-3-hadoop容器中的yarn集群配置" tabindex="-1">4.3 Hadoop容器中的YARN集群配置 <a class="header-anchor" href="#_4-3-hadoop容器中的yarn集群配置" aria-label="Permalink to &quot;4.3 Hadoop容器中的YARN集群配置&quot;">​</a></h3><p>由于YARN的架构中有二个角色，主角色ResourceManager，从角色 NodeManager。</p><p>因此我们需要给每个hadoop容器去分配这些角色。分配结果如下表所示。</p><table tabindex="0"><thead><tr><th>节点容器</th><th>所分配的角色</th></tr></thead><tbody><tr><td>hadoop01 容器</td><td>ResourceManager主角色节点，NodeManager从角色节点，ProxyServer代理服务器JobHistoryServer日志记录。</td></tr><tr><td>hadoop02 容器</td><td>NodeManager从角色节点。</td></tr><tr><td>hadoop03 容器</td><td>NodeManager从角色节点。</td></tr></tbody></table><blockquote><p>配置方式</p></blockquote><ol><li>启动主角色ResourceManager节点。</li><li>启动从角色NodeManager节点。</li><li>开启ProxyServer代理服务器，从而给YARN提供安全性，和WEB界面。</li><li>开启JobHistoryServer记录各个YARN节点的日志信息。</li></ol><p>先修改hadoop01主节点容器中的配置，然后复制给其他hadoop容器中。</p><blockquote><p>① 编辑yarn-env.sh文件</p></blockquote><p>在hadoop01容器中，编辑 /usr/local/hadoop/etc/hadoop/yarn-env.sh文件</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置JAVA_HOME环境变量</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JAVA_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置hadoop_home环境变量</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置hadoop配置文件路径</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_CONF_DIR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop/etc/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置hadoop日志文件路径</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_LOG_DIR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop/logs</span></span></code></pre></div><blockquote><p>② 编辑yarn-site.xml文件</p></blockquote><p>在hadoop01容器中，编辑 /usr/local/hadoop/etc/hadoop/yarn-site.xml文件</p><div class="language-xml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">xml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置ResourceManager主角色节点的位置 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.resourcemanager.hostname&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置resourcemanager的IP端口 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.resourcemanager.webapp.address&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01:8088&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 为MapReduce程序开启shuffle服务 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.nodemanager.aux-services&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce_shuffle&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.application.classpath&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/etc/hadoop,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/share/hadoop/common/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/share/hadoop/common/lib/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/share/hadoop/hdfs/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/share/hadoop/hdfs/lib/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/share/hadoop/mapreduce/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/share/hadoop/mapreduce/lib/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/share/hadoop/yarn/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            \${HADOOP_HOME}/share/hadoop/yarn/lib/*</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span></code></pre></div><blockquote><p>③ 文件转发</p></blockquote><p>将hadoop01容器中修改好的配置文件，都复制到其他hadoop容器中。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop02容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02:/usr/local</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop03容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03:/usr/local</span></span></code></pre></div><p>以上YARN集群配置就完成了</p><h3 id="_5-启动hdfs集群" tabindex="-1">5.启动HDFS集群 <a class="header-anchor" href="#_5-启动hdfs集群" aria-label="Permalink to &quot;5.启动HDFS集群&quot;">​</a></h3><p><span style="color:red;">注意：下面只需要在NameNode主角色节点的Hadoop容器（即hadoop01容器）终端中执行下面命令即可。</span></p><blockquote><p>格式化HDFS集群</p></blockquote><p>先格式化HDFS集群,清除现有的文件数据和元数据。这个命令在第一次启动 HDFS 集群时使用，从而确保 NameNode 和 DataNode 存储的数据是干净的。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 格式化namenode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hdfs</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> namenode</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -format</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 假如遇到命令未找到的错误。表示环境变量可能未配置好。可以用绝对路径来运行该命令。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/bin/hdfs</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> namenode</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -format</span></span></code></pre></div><p>如图所示表示格式化成功 <img src="`+o+`" alt="hadoop_20240704170512.png"></p><blockquote><p>启动HDFS集群/关闭HDFS集群</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 启动hdfs集群</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">start-dfs.sh</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 或者绝对路径下的启动hdfs集群</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/sbin/start-dfs.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 关闭hdfs集群</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">stop-dfs.sh</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 或者绝对路径下的关闭hdfs集群</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/sbin/stop-dfs.sh</span></span></code></pre></div><p>如图所示启动HDFS集群成功 <img src="`+r+`" alt="hadoop_20240705092922.png"></p><blockquote><p>查询各个hadoop容器的java进程</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop01容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 如果jps命令，提示找不到。可以用绝对路径的jps命令。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> /usr/local/jdk1.8/bin/jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1170</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NameNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1371</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">2044</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1629</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> SecondaryNameNode</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop02容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">247</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">394</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop03容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">993</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">599</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">701</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NodeManager</span></span></code></pre></div><p>通过jps命令。我们可以看到hadoop01容器启动了NameNode，DataNode，SecondaryNameNode进程。hadoop02容器启动了DataNode进程。hadoop03容器启动了DataNode进程。</p><blockquote><p>浏览器中访问<code>http://localhost:50070</code></p></blockquote><p>如图是Hadoop中HDFS文件服务系统的管理页面。该网页是在NameNode主角色节点所在的容器（即Hadoop01容器）中。 <img src="`+E+'" alt="hadoop_20240705104632.png"></p><p>如图是三个DataNode节点信息 <img src="'+g+`" alt="hadoop_20240705174750.png"></p><h3 id="_6-启动yarn集群" tabindex="-1">6.启动YARN集群 <a class="header-anchor" href="#_6-启动yarn集群" aria-label="Permalink to &quot;6.启动YARN集群&quot;">​</a></h3><blockquote><p>一键启动/停止YARN集群命令</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 一键启动</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">start-yarn.sh</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 或者</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/sbin/start-yarn.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 一键停止</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">stop-yarn.sh</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 或者</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/sbin/stop-yarn.sh</span></span></code></pre></div><p>该命令会根据yarn-site.xml配置文件中的<code>yarn.resourcemanager.hostname</code>属性来选择在那台服务器上作为ResourceManager主角色启动。也会根据worker文件配置的服务器来作为NodeManager从角色启动。</p><p>如图启动ResourceManager进程和NodeManager进程。 <img src="`+y+`" alt="hadoop_20240710155943.png"></p><blockquote><p>查询各个hadoop容器的java进程</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop01容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">5861</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4487</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4744</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> SecondaryNameNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">5325</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NodeManager</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4285</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NameNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">5134</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ResourceManager</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop02容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1158</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NodeManager</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1320</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1022</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop03容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1158</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NodeManager</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1320</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1022</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span></code></pre></div><p>通过jps命令。我们可以看到hadoop01容器还额外启动了ResourceManager，NodeManager进程。hadoop02容器额外启动了NodeManager进程。hadoop03容器额外启动了NodeManager进程。</p><p>这表示YARN集群正常启动了。</p><blockquote><p>单独启动/停止YARN进程</p></blockquote><p>我们还可以在某台服务器上，单独启动/停止该服务器的ResourceManager进程，NodeManager和proxyserver 进程。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 单独启动/关闭进程命令如下</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/bin/yarn</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --daemon</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">stop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> resourcemanager</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nodemanager</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">proxyserver</span></span></code></pre></div><blockquote><p>单独启动/停止历史服务器，命令如下</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/bin/mapred</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --daemon</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">stop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> historyserver</span></span></code></pre></div><blockquote><p>浏览器中访问<code>http://localhost:38088</code></p></blockquote><p>如图是Hadoop中YARN集群的管理页面。</p><p><img src="`+c+'" alt="hadoop_20240710164433.png"></p>',203)]))}const H=i(F,[["render",u]]);export{v as __pageData,H as default};
