<!DOCTYPE html>
<html lang="Zh_CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hadoop笔记1 | Shuyx Blog</title>
    <meta name="description" content="Shuyx Blog 是一个基于 VuePress 的静态博客网站。">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.CXNiKVgG.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.cTDFr1KL.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.0aTSOFDJ.js">
    <link rel="modulepreload" href="/assets/chunks/framework.CmzJUe0_.js">
    <link rel="modulepreload" href="/assets/blogs_ApacheHadoop_Hadoop笔记1.md.BJmkxAZA.lean.js">
    <link rel="icon" href="/favicon.ico">
    <script>var _hmt=_hmt||[];(function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?58657c617e14a7184e841a80d36a78ce";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)})();</script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a9a9e638><!--[--><!--]--><!--[--><span tabindex="-1" data-v-492508fc></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-492508fc>Skip to content</a><!--]--><!----><header class="VPNav" data-v-a9a9e638 data-v-f1e365da><div class="VPNavBar" data-v-f1e365da data-v-822684d1><div class="wrapper" data-v-822684d1><div class="container" data-v-822684d1><div class="title" data-v-822684d1><div class="VPNavBarTitle" data-v-822684d1 data-v-0f4f798b><a class="title" href="/" data-v-0f4f798b><!--[--><!--]--><!--[--><img class="VPImage logo" src="/logo.png" alt data-v-35a7d0b8><!--]--><span data-v-0f4f798b>Shuyx Blog</span><!--[--><!--]--></a></div></div><div class="content" data-v-822684d1><div class="content-body" data-v-822684d1><!--[--><!--]--><div class="VPNavBarSearch search" data-v-822684d1><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-822684d1 data-v-e6d46098><span id="main-nav-aria-label" class="visually-hidden" data-v-e6d46098> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>🏠️ 首页</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pages/views/ArticleCategory.html" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>🗂️ 分类</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pages/views/ArticleTag.html" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>🏷️ 标签</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pages/views/Archives.html" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>📑 归档</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pages/views/NavigationWebsite.html" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>🧭 导航</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/blogs/%E9%9D%A2%E8%AF%95/README.html" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>🧑🏻‍💻 面试</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pages/views/CommentView.html" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>🦜 留言板</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>🍉 关于</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/blogs/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/%E5%85%B3%E4%BA%8E%E6%88%91.html" data-v-acbfed09><!--[--><span data-v-acbfed09>关于我</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link vp-external-link-icon" href="https://github.com/suichentree" target="_blank" rel="noreferrer" data-v-acbfed09><!--[--><span data-v-acbfed09>Github</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link vp-external-link-icon" href="https://gitee.com/suichentree" target="_blank" rel="noreferrer" data-v-acbfed09><!--[--><span data-v-acbfed09>Gitee</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link vp-external-link-icon" href="https://weixin.qq.com/" target="_blank" rel="noreferrer" data-v-acbfed09><!--[--><span data-v-acbfed09>微信</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link vp-external-link-icon" href="https://juejin.cn/user/xxxxxx" target="_blank" rel="noreferrer" data-v-acbfed09><!--[--><span data-v-acbfed09>掘金</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link vp-external-link-icon" href="https://blog.csdn.net/xxxx" target="_blank" rel="noreferrer" data-v-acbfed09><!--[--><span data-v-acbfed09>CSDN</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-822684d1 data-v-c80d9ad0 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><span class="vpi-languages option-icon" data-v-04f5c5e9></span><!----><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--[--><div class="items" data-v-c80d9ad0><p class="title" data-v-c80d9ad0>简体中文</p><!--[--><div class="VPMenuLink" data-v-c80d9ad0 data-v-acbfed09><a class="VPLink link" href="/en/blogs/ApacheHadoop/Hadoop笔记1.html" data-v-acbfed09><!--[--><span data-v-acbfed09>English</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-822684d1 data-v-af096f4a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-af096f4a data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-822684d1 data-v-164c457f data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/suichentree" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="https://gitee.com/suichenTree" aria-label target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><svg t="1721906075888" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2472" width="256" height="256"><path d="M512 0C230.4 0 0 230.4 0 512s230.4 512 512 512 512-230.4 512-512S793.6 0 512 0z m284.8 313.6c0 12.8-12.8 25.6-25.6 25.6H416c-41.6 0-76.8 35.2-76.8 76.8v243.2c0 12.8 12.8 25.6 25.6 25.6h240c41.6 0 76.8-35.2 76.8-76.8v-12.8c0-12.8-12.8-25.6-25.6-25.6H480c-12.8 0-25.6-12.8-25.6-25.6v-64c0-12.8 12.8-25.6 25.6-25.6h291.2c12.8 0 25.6 12.8 25.6 25.6v144c0 92.8-76.8 169.6-169.6 169.6H252.8c-12.8 0-25.6-12.8-25.6-25.6V412.8C227.2 310.4 310.4 224 416 224h355.2c12.8 0 25.6 12.8 25.6 25.6v64z" fill="#B32225" p-id="2473"></path></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-822684d1 data-v-925effce data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-04f5c5e9><span class="vpi-more-horizontal icon" data-v-04f5c5e9></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--[--><div class="group translations" data-v-925effce><p class="trans-title" data-v-925effce>简体中文</p><!--[--><div class="VPMenuLink" data-v-925effce data-v-acbfed09><a class="VPLink link" href="/en/blogs/ApacheHadoop/Hadoop笔记1.html" data-v-acbfed09><!--[--><span data-v-acbfed09>English</span><!--]--></a></div><!--]--></div><div class="group" data-v-925effce><div class="item appearance" data-v-925effce><p class="label" data-v-925effce>日夜模式</p><div class="appearance-action" data-v-925effce><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-925effce data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div></div></div><div class="group" data-v-925effce><div class="item social-links" data-v-925effce><div class="VPSocialLinks social-links-list" data-v-925effce data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/suichentree" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-github"></span></a><a class="VPSocialLink no-icon" href="https://gitee.com/suichenTree" aria-label target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><svg t="1721906075888" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2472" width="256" height="256"><path d="M512 0C230.4 0 0 230.4 0 512s230.4 512 512 512 512-230.4 512-512S793.6 0 512 0z m284.8 313.6c0 12.8-12.8 25.6-25.6 25.6H416c-41.6 0-76.8 35.2-76.8 76.8v243.2c0 12.8 12.8 25.6 25.6 25.6h240c41.6 0 76.8-35.2 76.8-76.8v-12.8c0-12.8-12.8-25.6-25.6-25.6H480c-12.8 0-25.6-12.8-25.6-25.6v-64c0-12.8 12.8-25.6 25.6-25.6h291.2c12.8 0 25.6 12.8 25.6 25.6v144c0 92.8-76.8 169.6-169.6 169.6H252.8c-12.8 0-25.6-12.8-25.6-25.6V412.8C227.2 310.4 310.4 224 416 224h355.2c12.8 0 25.6 12.8 25.6 25.6v64z" fill="#B32225" p-id="2473"></path></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-822684d1 data-v-5dea55bf><span class="container" data-v-5dea55bf><span class="top" data-v-5dea55bf></span><span class="middle" data-v-5dea55bf></span><span class="bottom" data-v-5dea55bf></span></span></button></div></div></div></div><div class="divider" data-v-822684d1><div class="divider-line" data-v-822684d1></div></div></div><!----></header><div class="VPLocalNav empty fixed" data-v-a9a9e638 data-v-070ab83d><div class="container" data-v-070ab83d><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-070ab83d data-v-168ddf5d><button data-v-168ddf5d>Return to top</button><!----></div></div></div><!----><div class="VPContent" id="VPContent" data-v-a9a9e638 data-v-91765379><div class="VPDoc has-aside" data-v-91765379 data-v-83890dd9><!--[--><!--]--><div class="container" data-v-83890dd9><div class="aside" data-v-83890dd9><div class="aside-curtain" data-v-83890dd9></div><div class="aside-container" data-v-83890dd9><div class="aside-content" data-v-83890dd9><div class="VPDocAside" data-v-83890dd9 data-v-6d7b3c46><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-6d7b3c46 data-v-b38bf2ff><div class="content" data-v-b38bf2ff><div class="outline-marker" data-v-b38bf2ff></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b38bf2ff>文章大纲目录</div><ul class="VPDocOutlineItem root" data-v-b38bf2ff data-v-3f927ebe><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-6d7b3c46></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-83890dd9><div class="content-container" data-v-83890dd9><!--[--><!--[--><!--[--><!--[--><div class="fdate"><div> 🗂️ 文章分类： <!--[--><span>大数据  </span><!--]--></div></div><div class="fdate"><div> 🏷️ 文章标签： <!--[--><span>Hadoop  </span><!--]--></div></div><div class="fdate">📝 文章创建时间： 2024-07-01</div><div class="fdate">🔥 文章最后更新时间：暂无</div><!--]--><!--]--><!--]--><!--]--><main class="main" data-v-83890dd9><div style="position:relative;" class="vp-doc _blogs_ApacheHadoop_Hadoop%E7%AC%94%E8%AE%B01" data-v-83890dd9><div><p>[toc]</p><h1 id="hadoop笔记1" tabindex="-1">Hadoop笔记1 <a class="header-anchor" href="#hadoop笔记1" aria-label="Permalink to &quot;Hadoop笔记1&quot;">​</a></h1><p>当前使用版本为： hadoop-3.3.6</p><h2 id="大数据介绍" tabindex="-1">大数据介绍 <a class="header-anchor" href="#大数据介绍" aria-label="Permalink to &quot;大数据介绍&quot;">​</a></h2><p>狭义上：大数据是指一类技术栈，用来对海量数据进行处理的软件技术体系。 广义上：大数据是指数字化时代，信息化时代的基础数据支撑，用数据为生活赋能。</p><blockquote><p>大数据的核心工作是什么？</p></blockquote><ul><li>数据存储：可以存储海量待处理数据。</li><li>数据计算：可以从海量数据中计算挖掘出有价值的数据结果。</li><li>数据传输：可以将海量数据传输给各个目标。</li></ul><blockquote><p>大数据软件技术生态有哪些？</p></blockquote><p>由于大数据的核心工作分别是: 数据存储，数据计算，数据传输。</p><p>对于数据存储方面：</p><ul><li>Apache Hadoop框架的HDFS组件是大数据技术体系中使用最广泛的分布式存储技术。</li><li>Apache HBase是大数据技术体系中使用最广泛的NoSQL，K-V键值对数据库技术。HBase是在HDFS的基础上构建的。</li><li>Apache KUDU 也是大数据技术系统中使用较多的分布式存储引擎。</li><li>除此之外，还有各个云平台提供的大数据存储服务。例如阿里云的OSS,亚马逊的S3云存储等都可以替代。</li></ul><p>对于数据计算方面：</p><ul><li>Apache Hadoop框架的MapReduce组件是最早的大数据分布式计算引擎。</li><li>Apache Hive 框架是一款以SQL为开发语言的分布式计算框架。其底层使用了Hadoop框架的MapReduce组件技术。</li><li>Apache Spark 是目前全球内最火热的分布式内存计算引擎技术。</li><li>Apache Flink 同样也是一款大数据分布式内存计算引擎，主要在实时计算（流计算）领域，Flink占据主流。</li></ul><p>对于数据传输方面：</p><ul><li>Apache Kafka 是一款分布式消息系统，可以完成海量数据的数据传输工作。</li><li>Apache Pulsar 同样也是一款分布式的消息系统。</li><li>Apache Flume 是一款流式数据采集工具，可以从非常多的数据源中进行数据采集。</li><li>..............</li></ul><h2 id="hadoop介绍" tabindex="-1">Hadoop介绍 <a class="header-anchor" href="#hadoop介绍" aria-label="Permalink to &quot;Hadoop介绍&quot;">​</a></h2><p>Hadoop的全称是Apache Hadoop。</p><p>当前使用版本为： hadoop-3.3.6</p><p>Hadoop是Apache软件基金会下的顶级开源项目。Hadoop的主要功能如下。</p><ul><li>分布式数据存储</li><li>分布式数据计算</li><li>分布式资源调度</li></ul><p>总结：Hadoop是一个开源的分布式软件框架。提供分布式存储，计算，资源调度的解决方案。开发者可以通过Hadoop来实现海量数据的存储和计算。</p><blockquote><p>Hadoop内部存在三大组件，分别是：</p></blockquote><ul><li>HDFS组件： HDFS是Hadoop内部的分布式存储组件。可以用来构建分布式文件系统，存储海量数据。</li><li>MapReduce组件：MapReduce是Hadoop内部的分布式计算组件，提供接口给用户进行分布式计算。</li><li>YARN组件: YARN是Hadoop内部的分布式资源调度组件。可以帮助用户实现大规模集群的资源调度。</li></ul><p><img src="/assets/hadoop_20240701173106.D5hIoduX.png" alt="hadoop_20240701173106.png"></p><h3 id="hdfs分布式文件系统-介绍" tabindex="-1">HDFS分布式文件系统-介绍 <a class="header-anchor" href="#hdfs分布式文件系统-介绍" aria-label="Permalink to &quot;HDFS分布式文件系统-介绍&quot;">​</a></h3><p>HDFS 分布式文件系统 是 Hadoop 的三大组件之一。</p><ul><li>HDFS 全称是 Hadoop Distribued File System (Hadoop 分布式文件系统)</li><li>HDFS 是 Hadoop内部的分布式数据存储解决方案。</li><li>HDFS 可以在多台服务器上进行集群部署，并且存储海量的数据。</li></ul><blockquote><p>为什么需要分布式文件存储？</p></blockquote><p>由于单个服务器的数据存储能力是有上限的，因此当数据量大到一定程度的时候，需要多台服务器一起存储数据才行。</p><blockquote><p>HDFS的集群架构</p></blockquote><p>HDFS的集群架构是主从模式的，即有一个主节点，多个从节点，共同组成的集群。</p><p>在HDFS的集群架构中，主要有三种不同的角色。</p><ul><li>主角色 NameNode ：主角色是一个独立进程。主要负责管理整个HDFS系统，管理DataNode从角色。</li><li>从角色 DataNode ：从角色也是一个独立进程。主要负责数据存储。</li><li>辅助角色 SecondaryNameNode ：辅助角色也是一个独立进程。主要负责辅助主角色，帮助主角色完成元数据整理工作。</li></ul><p>HDFS的集群架构如下图所示 <img src="/assets/hadoop_20240702165036.Bc7f9V0M.png" alt="hadoop_20240702165036.png"></p><h3 id="mapreduce分布式计算-介绍" tabindex="-1">MapReduce分布式计算-介绍 <a class="header-anchor" href="#mapreduce分布式计算-介绍" aria-label="Permalink to &quot;MapReduce分布式计算-介绍&quot;">​</a></h3><blockquote><p>什么是分布式计算？</p></blockquote><p>分布式计算是指通过多台服务器协同工作，共同完成一个计算任务。从而得到计算结果。</p><p>分布式计算的2种工作模式：</p><ol><li>分散汇总模式。（Hadoop的MapReduce使用的就是这种模式）</li><li>中心调度，步骤执行模式。（Spark,Flink框架使用这种模式）</li></ol><blockquote><p>什么是MapReduce？</p></blockquote><p>MapReduce使用的是分散汇总模式的分布式计算框架。也是Hadoop内部的分布式计算的组件。</p><p>MapReduce框架内部提供了两大接口。</p><ul><li>Map分散接口，由服务器对数据进行分布式处理。</li><li>Reduce聚合接口，将分布式的处理结果进行汇总统计。</li></ul><p style="color:red;"> 注意：MapReduce提供了Map分散接口和Reduce聚合接口，给开发者使用。但是由于年代久远，MapReduce框架的代码，性能已经过时了。 </p><p style="color:red;"> 因此，现在主要使用Apache Hive框架来进行分布式计算。Apache Hive框架底层使用的就是MapReduce框架，所以我们只需对MapReduce框架简单了解即可。 </p><blockquote><p>MapReduce的运行机制</p></blockquote><ol><li>MapReduce会将一个计算任务，分解成多个小的Map Task（分散任务） 和 Reduce Task（聚合任务）。</li><li>然后将Map Task（分散任务） 和 Reduce Task（聚合任务）分配到对应的服务器中去进行计算。</li><li>最后将多个服务器中的计算结果通过Reduce Task（聚合任务）聚合到一起。从而得到这个计算任务的计算结果。</li></ol><h3 id="yarn分布式资源调度-介绍" tabindex="-1">YARN分布式资源调度-介绍 <a class="header-anchor" href="#yarn分布式资源调度-介绍" aria-label="Permalink to &quot;YARN分布式资源调度-介绍&quot;">​</a></h3><blockquote><p>什么是分布式资源调度？</p></blockquote><p>资源通常是指服务器的硬件资源。例如CPU，内存，硬盘，网络等。资源调度的目的是最大化的利用服务器的硬件资源。</p><p>分布式资源调度是指管理整个分布式服务器集群的全部资源，并进行统一调度。</p><blockquote><p>什么是YARN?</p></blockquote><p>YARN是Hadoop内部的分布式资源调度组件，可以将Hadoop的资源统一管理，并进行分配。</p><blockquote><p>MapReduce 和 YARN 的关系？</p></blockquote><p>YARN 统一分配资源给MapReduce使用，而MapReduce需要这些资源才能进行分布式计算。</p><blockquote><p>YARN的集群架构</p></blockquote><p>YARN的集群架构是主从模式的，即有一个主节点，多个从节点，共同组成的集群。</p><p>在YARN的集群架构中，主要有2种不同的角色。</p><ul><li>主角色 ResourceManager ：主角色负责整个集群的资源调度，协调各个从角色所需要的资源。</li><li>从角色 NodeManager ：从角色主要负责调度的单个服务器上的资源给程序使用。</li></ul><p>YARN的集群架构如下图所示 <img src="/assets/hadoop_20240709164126.BoJ0Mfv0.png" alt="hadoop_20240709164126.png"></p><h2 id="hadoop的安装和部署" tabindex="-1">Hadoop的安装和部署 <a class="header-anchor" href="#hadoop的安装和部署" aria-label="Permalink to &quot;Hadoop的安装和部署&quot;">​</a></h2><p>下面是在docker环境中安装和部署Hadoop的。</p><p>由于目前dockerhub中的Hadoop镜像都是旧的镜像格式，最新版本的docker无法下载该镜像。</p><p>当尝试下载官方的Hadoop镜像时，会提示该Hadoop镜像是旧的镜像格式，不建议下载使用。 <img src="/assets/hadoop_20240703161546.Jde1ZdqQ.png" alt="hadoop_20240703161546.png"></p><p>因此下面的笔记是先在centos镜像的基础上安装部署java和hadoop。从而构建出Hadoop镜像。</p><h3 id="_1-构建hadoop镜像" tabindex="-1">1.构建Hadoop镜像 <a class="header-anchor" href="#_1-构建hadoop镜像" aria-label="Permalink to &quot;1.构建Hadoop镜像&quot;">​</a></h3><ol><li>先下载centos镜像</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> pull</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> centos:7</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> images</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> #查看镜像</span></span></code></pre></div><ol start="2"><li>构建Hadoop镜像</li></ol><p>在centos镜像的基础上安装SSH服务,java，hadoop。然后通过Dockerfile构建出一个新镜像。</p><p>步骤1：创建Dockerfile文件。该文件名称就是Dockerfile，注意该文件没有后缀名。</p><p>步骤2：编辑Dockerfile文件。内容如下所示。</p><p>注意：在Dockerfile所在目录下提前准备好 jdk-8u202-linux-x64.tar.gz 与 hadoop-3.3.6.tar.gz 安装包。当然你也可以准备其他版本的安装包。</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># FROM:基于什么镜像来制作自己的镜像</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">FROM</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> centos:7</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># MAINTAINER:表示该镜像的作者（维护者）</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">MAINTAINER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> shuyx</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置yum源，包括修改仓库地址、提速、更新</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> cd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/yum.repos.d/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sed</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;s/mirrorlist/#mirrorlist/g&#39;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/yum.repos.d/CentOS-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">*</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sed</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;s|#baseurl=http://mirror.centos.org|baseurl=http://mirrors.aliyun.com|g&#39;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/yum.repos.d/CentOS-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">*</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> makecache</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> update</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 安装ssh服务和ssh客户端。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> openssh-server</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sudo</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sed</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -i</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;s/UsePAM yes/UsePAM no/g&#39;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/ssh/sshd_config</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> openssh-clients</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 生成ssh密钥，注意此处设置了root用户的密码为root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> echo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;root:root&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> chpasswd</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> echo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;root   ALL=(ALL)       ALL&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> &gt;&gt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/sudoers</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ssh-keygen</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> dsa</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/ssh/ssh_host_dsa_key</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ssh-keygen</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> rsa</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/ssh/ssh_host_rsa_key</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 开启ssh服务，暴露SSH的默认端口22。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> mkdir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /var/run/sshd</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">EXPOSE</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 22</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">CMD</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;/usr/sbin/sshd&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;-D&quot;]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将本地的jdk安装包，复制到容器的/usr/local/目录中。并进行解压，配置环境变量</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ADD</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> jdk-8u202-linux-x64.tar.gz</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> mv</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/jdk1.8.0_202</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> JAVA_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> PATH</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> $JAVA_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/bin:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将本地的hadoop安装包，复制到容器的/usr/local/目录中。并进行解压，配置环境变量</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ADD</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop-3.3.6.tar.gz</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> mv</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop-3.3.6</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HADOOP_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> PATH</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> $HADOOP_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/bin:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> PATH</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> $HADOOP_HOME</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">/sbin:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$PATH</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定root用户访问</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_NAMENODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_DATANODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_SECONDARYNAMENODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> YARN_RESOURCEMANAGER_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> YARN_NODEMANAGER_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 安装 which,sudo,vim 命令行工具</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">RUN</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> yum</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -y</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> which</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> sudo</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> vim</span></span></code></pre></div><p>步骤3：在Dockerfile文件的同目录中，使用下面的命令，创建新镜像my-hadoop-image</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># &quot;.&quot;表示当前目录，即Dockerfile所在的位置</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># my-hadoop-image 为新镜像的名称</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> build</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-image</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> .</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询新镜像my-hadoop-image</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> images</span></span></code></pre></div><h3 id="_2-部署hadoop容器" tabindex="-1">2.部署Hadoop容器 <a class="header-anchor" href="#_2-部署hadoop容器" aria-label="Permalink to &quot;2.部署Hadoop容器&quot;">​</a></h3><ol><li>先创建一个docker网络。这样能很方便的让多个Hadoop容器之间互相通信。</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建一个docker网络</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> create</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-net</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询网络</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ls</span></span></code></pre></div><ol start="2"><li>创建多个Hadoop容器</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建hadoop01容器</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -itd</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-net</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --name</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop01</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 50070:50070</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 38088:8088</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-image</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建hadoop02容器</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -itd</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-net</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --name</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-image</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建hadoop03容器</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">docker</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -itd</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --network</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-net</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --name</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> my-hadoop-image</span></span></code></pre></div><p>50070和8088端口，主要是用来在浏览器中访问hadoop WEB界面的。</p><ol start="3"><li>测试容器内的java，hadoop是否安装成功</li></ol><p>在每一个容器终端中执行下面命令</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 查询安装的java,hadoop版本</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">java</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -version</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> version</span></span></code></pre></div><p>安装结果如下图所示 <img src="/assets/hadoop_20240704093254.XP8BH5cE.png" alt="hadoop_20240704093254.png"></p><ol start="4"><li>hadoop安装包中的目录结构</li></ol><p><img src="/assets/hadoop_20240704102116.CsVrpseg.png" alt="hadoop_20240704102116.png"></p><h3 id="hadoop服务授权给普通用户-可选" tabindex="-1">Hadoop服务授权给普通用户（可选） <a class="header-anchor" href="#hadoop服务授权给普通用户-可选" aria-label="Permalink to &quot;Hadoop服务授权给普通用户（可选）&quot;">​</a></h3><p>通常在测试环境中，我们可以使用root用户来操作 Hadoop 中的服务组件。但是在生产环境中，强烈建议避免以 root 用户身份直接操作 Hadoop 的组件，这有助于减少安全风险。</p><p>因此为了确保数据安全，生产环境中的hadoop系统不以root用户启动。我们可以创建普通用户hadoop，并且以普通用户hadoop来操作整个hadoop服务。</p><blockquote><p>在Hadoop容器中创建普通用户hadoop</p></blockquote><p>在每一个Hadoop容器终端中,执行下面几条命令</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建普通用户hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">useradd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置hadoop用户的密码为123456</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">passwd</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将当前用户从root用户切换到hadoop用户</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">su</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> -</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span></code></pre></div><blockquote><p>Hadoop容器中的hadoop相关目录文件授权给普通用户hadoop</p></blockquote><p>我们需要把Hadoop容器中的hadoop相关目录授权给之前创建的普通用户hadoop</p><p>在每一个Hadoop容器终端中,执行下面命令。注意需要用root用户来执行该命令</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 先切换到root用户，该命令需要输入root用户的密码root</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">su</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> -</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> root</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 执行授权命令</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">chown</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -R</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop:hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span></span></code></pre></div><blockquote><p>如果想要普通用户hadoop，也能有权限使用hadoop的服务。</p></blockquote><p>方式1： 在构建hadoop镜像的时候，将下面环境变量设定为hadoop用户访问</p><p>在Dockerfile文件中编辑下面内容。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定 hadoop 用户访问</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_NAMENODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_DATANODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> HDFS_SECONDARYNAMENODE_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> YARN_RESOURCEMANAGER_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ENV</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> YARN_NODEMANAGER_USER</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop</span></span></code></pre></div><p>方式2：在每一个hadoop容器中，进行环境变量的配置。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 编辑环境变量文件</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">vim</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /etc/profile</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop用户访问</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HDFS_NAMENODE_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HDFS_DATANODE_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HDFS_SECONDARYNAMENODE_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> YARN_RESOURCEMANAGER_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> YARN_NODEMANAGER_USER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hadoop</span></span></code></pre></div><h3 id="_3-hadoop容器之间互相配置ssh免密登录" tabindex="-1">3.Hadoop容器之间互相配置SSH免密登录 <a class="header-anchor" href="#_3-hadoop容器之间互相配置ssh免密登录" aria-label="Permalink to &quot;3.Hadoop容器之间互相配置SSH免密登录&quot;">​</a></h3><p>在每个Hadoop容器中，配置免密码互相SSH登录。方便多个Hadoop容器之间互相登录访问。也方便多个Hadoop容器之间互相传输文件。</p><ol><li>在每一个Hadoop容器终端中,执行下面几条命令</li></ol><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 先生成SSH密钥，一路回车即可</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh-keygen</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -t</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> rsa</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -b</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 4096</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置SSH免密登录。注意 hadoop01,hadoop02,hadoop03 是各个hadoop容器的名称。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 该命令会让你输入root用户的密码。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh-copy-id</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop01</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh-copy-id</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh-copy-id</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03</span></span></code></pre></div><p>由于多个hadoop容器在同一个网络中，因此hadoop容器互相可以通过容器名称找到其他hadoop容器。</p><ol start="2"><li>执行命令完毕后，hadoop01,hadoop02,hadoop03 三个容器之间就可以完成root用户之间的免密登录。</li><li>在Hadoop容器终端中进行测试</li></ol><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过ssh登录到hadoop01容器中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop01</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过ssh登录到hadoop02容器中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过ssh登录到hadoop03容器中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ssh</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03</span></span></code></pre></div><h3 id="_4-1-hadoop容器中的hdfs集群配置" tabindex="-1">4.1 Hadoop容器中的HDFS集群配置 <a class="header-anchor" href="#_4-1-hadoop容器中的hdfs集群配置" aria-label="Permalink to &quot;4.1 Hadoop容器中的HDFS集群配置&quot;">​</a></h3><p>由于HDFS分布式存储系统有三个角色，NameNode主角色，DataNode从角色，辅助角色SecondaryNameNode。</p><p>因此我们需要给每个hadoop容器去分配这些角色。分配结果如下表所示。</p><table tabindex="0"><thead><tr><th>节点容器</th><th>所分配的角色</th></tr></thead><tbody><tr><td>hadoop01 容器</td><td>NameNode主角色，DataNode从角色，辅助角色SecondaryNameNode。</td></tr><tr><td>hadoop02 容器</td><td>DataNode从角色</td></tr><tr><td>hadoop03 容器</td><td>DataNode从角色</td></tr></tbody></table><p>每个角色都相当于是一个进程或者一个节点，因此可以理解为三个Hadoop容器中存在5个进程节点。其中一个主进程节点NameNode，三个从进程节点DataNode，以及一个辅助进程节点SecondaryNameNode。</p><blockquote><p>配置方式</p></blockquote><p>HDFS集群配置需要对如下文件的修改</p><ul><li>workers 配置DataNode从角色是哪些。</li><li>hadoop-env.sh 配置hadoop的环境变量文件，需要将jdk的路径配置进去。</li><li>core-site.xml 是hadoop的核心配置，需要指定hadoop的基本配置信息。</li><li>hdfs-site.xml 是hadoop中的HDFS组件的配置文件。</li></ul><p><span style="color:red;">先配置hadoop01容器，然后将hadoop01容器中的hadoop目录整体复制到其他hadoop容器中即可。下面是在hadoop01容器中进行HDFS集群配置</span></p><blockquote><p>① 配置 workers 文件</p></blockquote><p>编辑/usr/local/hadoop/etc/hadoop/workers文件。配置三个DataNode从角色所在的hadoop容器名称。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注释默认的localhost</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># localhost</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop01</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop02</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop03</span></span></code></pre></div><p>由于三个hadoop容器都是在同一个网络my-hadoop-net下，容器可以用容器名称来找到其他hadoop容器。因此直接在workers文件中直接填写容器名称即可。</p><blockquote><p>② 配置 <code>hadoop-env.sh</code></p></blockquote><p>编辑 /usr/local/hadoop/etc/hadoop/hadoop-env.sh文件。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop使用的java环境的路径</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JAVA_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop的安装目录位置</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop配置文件的目录位置</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_CONF_DIR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop/etc/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop运行日志目录位置</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_LOG_DIR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop/logs</span></span></code></pre></div><blockquote><p>③ 配置core-site.xml</p></blockquote><p>编辑 /usr/local/hadoop/etc/hadoop/core-site.xml</p><div class="language-xml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">xml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 访问NameNode主角色的地址路径，hadoop01为NameNode主角色所在的容器名称。8020为通讯端口，端口可以随意指定，默认为8020端口 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;fs.defaultFS&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hdfs://hadoop01:8020&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!--文件缓冲区大小，为131702比特--&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;io.file.buffer.size&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;131702&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span></code></pre></div><blockquote><p>④ HDFS配置文件 hdfs-site.xml</p></blockquote><p>编辑 /usr/local/hadoop/etc/hadoop/hdfs-site.xml</p><div class="language-xml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">xml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置hdfs文件系统中，默认创建的文件权限 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.datanode.data.dir.perm&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;700&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- NameNode主角色节点中元数据存储位置 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.namenode.name.dir&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;file:/usr/local/hadoop/hdfs/namenode&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- NameNode主角色节点允许哪些DataNode从角色节点进行授权连接 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 此处填写DataNode从角色节点所在的容器名称即可 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.namenode.hosts&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01,hadoop02,hadoop03&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- DataNode从角色节点的数据存储目录 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.datanode.data.dir&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;file:/usr/local/hadoop/hdfs/datanode&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- hdfs数据块大小（以字节为单位，默认为128MB）--&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.blocksize&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;134217728&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 指定了 NameNode 提供 HTTP 服务的地址。通常用于浏览器访问 Hadoop 的管理界面 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;dfs.namenode.http-address&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01:50070&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span></code></pre></div><p>由于我们在hdfs-site.xml配置文件中，指定了namenode目录和datanode目录。因此我们还需要在NameNode主角色所在的hadoop容器中（即hadoop01容器），创建这两个目录。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">mkdir</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop/hdfs/namenode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">mkdir</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop/hdfs/datanode</span></span></code></pre></div><blockquote><p>⑤ 将hadoop01容器中的hadoop目录，复制到其他hadoop容器中</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop02容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02:/usr/local</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop03容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03:/usr/local</span></span></code></pre></div><p>scp命令需要输入root用户的密码，之前构建镜像的时候，设置了root用户密码为root。</p><p>以上关于Hadoop容器中的HDFS集群配置就完成了。</p><h3 id="_4-2-hadoop容器中的mapreduce配置" tabindex="-1">4.2 Hadoop容器中的MapReduce配置 <a class="header-anchor" href="#_4-2-hadoop容器中的mapreduce配置" aria-label="Permalink to &quot;4.2 Hadoop容器中的MapReduce配置&quot;">​</a></h3><blockquote><p>配置方式</p></blockquote><ol><li>无需启动任何进程。只需修改对应配置文件即可。</li></ol><p>先修改hadoop01主节点容器中的配置，然后复制给其他hadoop容器中。</p><blockquote><p>① 编辑mapred-env.sh文件</p></blockquote><p>在hadoop01容器中，编辑 /usr/local/hadoop/etc/hadoop/mapred-env.sh文件</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop使用的java环境的路径</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JAVA_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置JobHistoryServer进程的内存为1G</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_JOB_HISTORYSERVER_HEAPSIZE</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置日志级别为INFO</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_MAPRED_ROOT_LOGGER</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">INFO,RFA</span></span></code></pre></div><blockquote><p>② 编辑mapred-site.xml文件</p></blockquote><p>在hadoop01容器中，编辑 /usr/local/hadoop/etc/hadoop/mapred-site.xml文件</p><div class="language-xml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">xml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置MapReduce的运行框架为YARN --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.framework.name&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置jobhistory进程的通信端口 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.jobhistory.address&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01:10020&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置jobhistory进程的web端口 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.jobhistory.webapp.address&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01:19888&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置jobhistory进程的信息记录的路径 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;file:/usr/local/hadoop/mr-history/tmp&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置jobhistory进程的信息记录路径 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.jobhistory.done-dir&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;file:/usr/local/hadoop/mr-history/done&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置HADOOP_MAPRED_HOME环境变量 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.app.mapreduce.am.env&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置HADOOP_MAPRED_HOME环境变量 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.map.env&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置HADOOP_MAPRED_HOME环境变量 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce.reduce.env&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span></code></pre></div><ul><li>${HADOOP_HOME} 的值为/usr/local/hadoop。在构建Hadoop镜像的时候，就设置了该环境变量。</li></ul><blockquote><p>③ 文件转发</p></blockquote><p>将hadoop01容器中的修改好的配置文件，都复制到其他hadoop容器中。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop02容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02:/usr/local</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop03容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03:/usr/local</span></span></code></pre></div><p>以上MapReduce配置就完成了</p><h3 id="_4-3-hadoop容器中的yarn集群配置" tabindex="-1">4.3 Hadoop容器中的YARN集群配置 <a class="header-anchor" href="#_4-3-hadoop容器中的yarn集群配置" aria-label="Permalink to &quot;4.3 Hadoop容器中的YARN集群配置&quot;">​</a></h3><p>由于YARN的架构中有二个角色，主角色ResourceManager，从角色 NodeManager。</p><p>因此我们需要给每个hadoop容器去分配这些角色。分配结果如下表所示。</p><table tabindex="0"><thead><tr><th>节点容器</th><th>所分配的角色</th></tr></thead><tbody><tr><td>hadoop01 容器</td><td>ResourceManager主角色节点，NodeManager从角色节点，ProxyServer代理服务器JobHistoryServer日志记录。</td></tr><tr><td>hadoop02 容器</td><td>NodeManager从角色节点。</td></tr><tr><td>hadoop03 容器</td><td>NodeManager从角色节点。</td></tr></tbody></table><blockquote><p>配置方式</p></blockquote><ol><li>启动主角色ResourceManager节点。</li><li>启动从角色NodeManager节点。</li><li>开启ProxyServer代理服务器，从而给YARN提供安全性，和WEB界面。</li><li>开启JobHistoryServer记录各个YARN节点的日志信息。</li></ol><p>先修改hadoop01主节点容器中的配置，然后复制给其他hadoop容器中。</p><blockquote><p>① 编辑yarn-env.sh文件</p></blockquote><p>在hadoop01容器中，编辑 /usr/local/hadoop/etc/hadoop/yarn-env.sh文件</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置JAVA_HOME环境变量</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JAVA_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/jdk1.8</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置hadoop_home环境变量</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_HOME</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置hadoop配置文件路径</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_CONF_DIR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop/etc/hadoop</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 配置hadoop日志文件路径</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> HADOOP_LOG_DIR</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">/usr/local/hadoop/logs</span></span></code></pre></div><blockquote><p>② 编辑yarn-site.xml文件</p></blockquote><p>在hadoop01容器中，编辑 /usr/local/hadoop/etc/hadoop/yarn-site.xml文件</p><div class="language-xml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">xml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置ResourceManager主角色节点的位置 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.resourcemanager.hostname&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 设置resourcemanager的IP端口 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.resourcemanager.webapp.address&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;hadoop01:8088&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    &lt;!-- 为MapReduce程序开启shuffle服务 --&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.nodemanager.aux-services&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;mapreduce_shuffle&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;yarn.application.classpath&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/etc/hadoop,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/share/hadoop/common/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/share/hadoop/common/lib/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/share/hadoop/hdfs/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/share/hadoop/hdfs/lib/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/share/hadoop/mapreduce/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/share/hadoop/mapreduce/lib/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/share/hadoop/yarn/*,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            ${HADOOP_HOME}/share/hadoop/yarn/lib/*</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">value</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    &lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">property</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&lt;/</span><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">configuration</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">&gt;</span></span></code></pre></div><blockquote><p>③ 文件转发</p></blockquote><p>将hadoop01容器中修改好的配置文件，都复制到其他hadoop容器中。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop02容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop02:/usr/local</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在 hadoop01 容器的终端中把 /usr/local/hadoop 目录复制到 hadoop03容器的 /usr/local 目录中</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">scp</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -r</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /usr/local/hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop03:/usr/local</span></span></code></pre></div><p>以上YARN集群配置就完成了</p><h3 id="_5-启动hdfs集群" tabindex="-1">5.启动HDFS集群 <a class="header-anchor" href="#_5-启动hdfs集群" aria-label="Permalink to &quot;5.启动HDFS集群&quot;">​</a></h3><p><span style="color:red;">注意：下面只需要在NameNode主角色节点的Hadoop容器（即hadoop01容器）终端中执行下面命令即可。</span></p><blockquote><p>格式化HDFS集群</p></blockquote><p>先格式化HDFS集群,清除现有的文件数据和元数据。这个命令在第一次启动 HDFS 集群时使用，从而确保 NameNode 和 DataNode 存储的数据是干净的。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 格式化namenode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hdfs</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> namenode</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -format</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 假如遇到命令未找到的错误。表示环境变量可能未配置好。可以用绝对路径来运行该命令。</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/bin/hdfs</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> namenode</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -format</span></span></code></pre></div><p>如图所示表示格式化成功 <img src="/assets/hadoop_20240704170512.D9N8LRxd.png" alt="hadoop_20240704170512.png"></p><blockquote><p>启动HDFS集群/关闭HDFS集群</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 启动hdfs集群</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">start-dfs.sh</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 或者绝对路径下的启动hdfs集群</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/sbin/start-dfs.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 关闭hdfs集群</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">stop-dfs.sh</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 或者绝对路径下的关闭hdfs集群</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/sbin/stop-dfs.sh</span></span></code></pre></div><p>如图所示启动HDFS集群成功 <img src="/assets/hadoop_20240705092922.C2mLiBCs.png" alt="hadoop_20240705092922.png"></p><blockquote><p>查询各个hadoop容器的java进程</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop01容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 如果jps命令，提示找不到。可以用绝对路径的jps命令。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> /usr/local/jdk1.8/bin/jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1170</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NameNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1371</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">2044</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1629</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> SecondaryNameNode</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop02容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">247</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">394</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop03容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">993</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">599</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">701</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NodeManager</span></span></code></pre></div><p>通过jps命令。我们可以看到hadoop01容器启动了NameNode，DataNode，SecondaryNameNode进程。hadoop02容器启动了DataNode进程。hadoop03容器启动了DataNode进程。</p><blockquote><p>浏览器中访问<code>http://localhost:50070</code></p></blockquote><p>如图是Hadoop中HDFS文件服务系统的管理页面。该网页是在NameNode主角色节点所在的容器（即Hadoop01容器）中。 <img src="/assets/hadoop_20240705104632.D2FbmD3W.png" alt="hadoop_20240705104632.png"></p><p>如图是三个DataNode节点信息 <img src="/assets/hadoop_20240705174750.bxQqPsfu.png" alt="hadoop_20240705174750.png"></p><h3 id="_6-启动yarn集群" tabindex="-1">6.启动YARN集群 <a class="header-anchor" href="#_6-启动yarn集群" aria-label="Permalink to &quot;6.启动YARN集群&quot;">​</a></h3><blockquote><p>一键启动/停止YARN集群命令</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 一键启动</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">start-yarn.sh</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 或者</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/sbin/start-yarn.sh</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 一键停止</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">stop-yarn.sh</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 或者</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/sbin/stop-yarn.sh</span></span></code></pre></div><p>该命令会根据yarn-site.xml配置文件中的<code>yarn.resourcemanager.hostname</code>属性来选择在那台服务器上作为ResourceManager主角色启动。也会根据worker文件配置的服务器来作为NodeManager从角色启动。</p><p>如图启动ResourceManager进程和NodeManager进程。 <img src="/assets/hadoop_20240710155943.Cc6nOkJz.png" alt="hadoop_20240710155943.png"></p><blockquote><p>查询各个hadoop容器的java进程</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop01容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">5861</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4487</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4744</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> SecondaryNameNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">5325</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NodeManager</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4285</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NameNode</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">5134</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ResourceManager</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop02容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1158</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NodeManager</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1320</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1022</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># hadoop03容器终端</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1158</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> NodeManager</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1320</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1022</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> DataNode</span></span></code></pre></div><p>通过jps命令。我们可以看到hadoop01容器还额外启动了ResourceManager，NodeManager进程。hadoop02容器额外启动了NodeManager进程。hadoop03容器额外启动了NodeManager进程。</p><p>这表示YARN集群正常启动了。</p><blockquote><p>单独启动/停止YARN进程</p></blockquote><p>我们还可以在某台服务器上，单独启动/停止该服务器的ResourceManager进程，NodeManager和proxyserver 进程。</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 单独启动/关闭进程命令如下</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/bin/yarn</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --daemon</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">stop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> resourcemanager</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nodemanager</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">proxyserver</span></span></code></pre></div><blockquote><p>单独启动/停止历史服务器，命令如下</p></blockquote><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">/usr/local/hadoop/bin/mapred</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --daemon</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">stop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> historyserver</span></span></code></pre></div><blockquote><p>浏览器中访问<code>http://localhost:38088</code></p></blockquote><p>如图是Hadoop中YARN集群的管理页面。</p><p><img src="/assets/hadoop_20240710164433.Bi1575jT.png" alt="hadoop_20240710164433.png"></p></div></div></main><footer class="VPDocFooter" data-v-83890dd9 data-v-4f9813fa><!--[--><!--]--><!----><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter" data-v-a9a9e638 data-v-c970a860><div class="container" data-v-c970a860><p class="message" data-v-c970a860>Released under the MIT License.</p><p class="copyright" data-v-c970a860>Copyright © 2017-2025 present shuyx</p></div></footer><!--[--><div class="back-top-container" style="display:none;" data-v-c564d7dc><svg class="progress-ring" viewBox="0 0 100 100" data-v-c564d7dc><circle class="progress-ring-background" cx="50" cy="50" r="42" data-v-c564d7dc></circle><circle class="progress-ring-circle" cx="50" cy="50" r="42" style="stroke-dashoffset:263.89378290154264;" data-v-c564d7dc></circle></svg><div class="vitepress-backTop-main" title="返回顶部" data-v-c564d7dc><svg class="icon" viewBox="0 0 1024 1024" data-v-c564d7dc><path d="M752.736 431.063C757.159 140.575 520.41 8.97 504.518 0.41V0l-0.45 0.205-0.41-0.205v0.41c-15.934 8.56-252.723 140.165-248.259 430.653-48.21 31.457-98.713 87.368-90.685 184.074 8.028 96.666 101.007 160.768 136.601 157.287 35.595-3.482 25.232-30.31 25.232-30.31l12.206-50.095s52.47 80.569 69.304 80.528c15.114-1.23 87-0.123 95.6 0h0.82c8.602-0.123 80.486-1.23 95.6 0 16.794 0 69.305-80.528 69.305-80.528l12.165 50.094s-10.322 26.83 25.272 30.31c35.595 3.482 128.574-60.62 136.602-157.286 8.028-96.665-42.475-152.617-90.685-184.074z m-248.669-4.26c-6.758-0.123-94.781-3.359-102.891-107.192 2.95-98.714 95.97-107.438 102.891-107.93 6.964 0.492 99.943 9.216 102.892 107.93-8.11 103.833-96.174 107.07-102.892 107.192z m-52.019 500.531c0 11.838-9.42 21.382-21.012 21.382a21.217 21.217 0 0 1-21.054-21.34V821.74c0-11.797 9.421-21.382 21.054-21.382 11.591 0 21.012 9.585 21.012 21.382v105.635z m77.333 57.222a21.504 21.504 0 0 1-21.34 21.626 21.504 21.504 0 0 1-21.34-21.626V827.474c0-11.96 9.543-21.668 21.299-21.668 11.796 0 21.38 9.708 21.38 21.668v157.082z m71.147-82.043c0 11.796-9.42 21.34-21.053 21.34a21.217 21.217 0 0 1-21.013-21.34v-75.367c0-11.755 9.421-21.299 21.013-21.299 11.632 0 21.053 9.544 21.053 21.3v75.366z" fill="#FFF" data-v-c564d7dc></path></svg></div></div><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"blogs_apacheflink_flink笔记1.md\":\"B7FaiRpQ\",\"blogs_apachehadoop_hadoop笔记1.md\":\"BJmkxAZA\",\"blogs_apachehadoop_hadoop笔记2.md\":\"DmawrlRL\",\"blogs_apachehive_hive笔记1.md\":\"D-6aKjcP\",\"blogs_apachespark_spark笔记1.md\":\"CoTpN7X6\",\"blogs_apachespark_spark笔记2.md\":\"Cu0076af\",\"blogs_axios_axios.md\":\"FtO3sovP\",\"blogs_c_c__基础(1).md\":\"CSCRVi4z\",\"blogs_c_c语言基础(1).md\":\"ClJkkqBZ\",\"blogs_django_djangorestframework笔记1.md\":\"yUvagEOs\",\"blogs_django_djangorestframework笔记2.md\":\"DEswAtpe\",\"blogs_django_django笔记1.md\":\"Db4tRKL2\",\"blogs_django_django笔记2.md\":\"_z-8iITn\",\"blogs_docker_docker笔记1.md\":\"Cm3K6pO5\",\"blogs_docker_docker笔记2.md\":\"ybjKBu_5\",\"blogs_elasticsearch_elasticsearch笔记1.md\":\"B9LaXsCR\",\"blogs_elasticsearch_elasticsearch笔记2.md\":\"D0fe7FAO\",\"blogs_fastapi_fastapi笔记1.md\":\"ByyRKm3S\",\"blogs_fastapi_fastapi笔记2.md\":\"2Ewmbwil\",\"blogs_git_git笔记.md\":\"C1D5ZHVJ\",\"blogs_gitea_gitea笔记.md\":\"BmDFNo2m\",\"blogs_hibernate_hibernate.md\":\"By2Nycys\",\"blogs_html_flex布局.md\":\"Abff4HYO\",\"blogs_html_html-css基础笔记1.md\":\"CbLvB8iU\",\"blogs_idea_idea的笔记.md\":\"BLXftcVc\",\"blogs_java_java中常见的对象类型简述.md\":\"C5hEesB3\",\"blogs_java_java中的值传递.md\":\"CaWjDEvv\",\"blogs_java_java中的数据存储位置.md\":\"BWu6kZK3\",\"blogs_java_java笔记1-介绍.md\":\"DL7l6sh3\",\"blogs_java_java笔记10-异常.md\":\"CkATqSzr\",\"blogs_java_java笔记11-集合.md\":\"D0Anqwp-\",\"blogs_java_java笔记12-泛型.md\":\"CRnxbA9_\",\"blogs_java_java笔记13-枚举.md\":\"DQp_EigC\",\"blogs_java_java笔记14-反射.md\":\"DhxCd78v\",\"blogs_java_java笔记15-输入输出流.md\":\"DPb2EjRJ\",\"blogs_java_java笔记16-注解.md\":\"n8gRxDFL\",\"blogs_java_java笔记17-多线程.md\":\"pfoI9yUf\",\"blogs_java_java笔记17-锁.md\":\"B3qciLmC\",\"blogs_java_java笔记18-包装类与常用类.md\":\"kkzwS5bM\",\"blogs_java_java笔记19-lambda表达式.md\":\"BV0739rE\",\"blogs_java_java笔记2-基础语法.md\":\"BuICED9x\",\"blogs_java_java笔记3-流程控制.md\":\"D84B3eB5\",\"blogs_java_java笔记4-数组.md\":\"BN43z8PY\",\"blogs_java_java笔记6-类与对象.md\":\"BcxSWVtV\",\"blogs_java_java笔记7-类与对象2.md\":\"DDDzYYFA\",\"blogs_java_java笔记8-方法.md\":\"CfEXSWGJ\",\"blogs_java_java笔记8-继承.md\":\"CXDJuOXT\",\"blogs_java_java笔记9-内部类.md\":\"BfPecjB1\",\"blogs_java_java笔记9-多态.md\":\"DYSa63Vq\",\"blogs_java_java设计模式.md\":\"Bog9mpR4\",\"blogs_java_java详解hashmap.md\":\"CINgaDel\",\"blogs_java_readme.md\":\"DLcNnNSF\",\"blogs_javascript_es6.md\":\"CV7qWKKq\",\"blogs_javascript_javascript.md\":\"DGl6smZq\",\"blogs_javaweb_javaweb.md\":\"DJi6Jq_x\",\"blogs_jquery_jquery.md\":\"BKqmNfM2\",\"blogs_junit_junit.md\":\"BZTn7HJG\",\"blogs_jvm_jvm笔记.md\":\"NO0Y4FFN\",\"blogs_jwt_jwt笔记.md\":\"DmB4P73Y\",\"blogs_linux_linux mint操作系统笔记.md\":\"CK3r_Bd1\",\"blogs_linux_linux.md\":\"CBwhfp40\",\"blogs_linux_linux查询查找命令.md\":\"C-I5LMVk\",\"blogs_linux_linux软件包管理器.md\":\"Cf3tDEdq\",\"blogs_linux_telnet命令测试端口连通性.md\":\"Biij0wnr\",\"blogs_linux_云服务器(centos系统).md\":\"CxA2qIEc\",\"blogs_markdown_markdown.md\":\"ua0thkPr\",\"blogs_maven_maven笔记.md\":\"BD_lWvRD\",\"blogs_minio_minio笔记.md\":\"Dp46Hw6n\",\"blogs_minio_minio笔记2.md\":\"DGqBdpmz\",\"blogs_mongodb_mongodb.md\":\"CkSZXdOS\",\"blogs_mybatis_mybatis底层(1).md\":\"DbMVefMO\",\"blogs_mybatis_mybatis笔记1.md\":\"B6--xwj_\",\"blogs_mybatis_mybatis笔记2.md\":\"Dd79BeLr\",\"blogs_mybatis_mybatis笔记3.md\":\"aoG6m6FL\",\"blogs_mybatisplus_mybatis-plus.md\":\"BMI4EmEh\",\"blogs_mybatisplus_mybatisplus代码生成器笔记.md\":\"C7NMEEEP\",\"blogs_mybatisplus_mybatisplus扩展笔记.md\":\"DJeTdcZA\",\"blogs_mybatisplus_mybatisplus笔记.md\":\"CxJGIS46\",\"blogs_mysql_mysql的常见问题.md\":\"DDST9z-n\",\"blogs_mysql_mysql笔记1.md\":\"4s33wCD5\",\"blogs_mysql_mysql笔记10-事务.md\":\"C7Shamop\",\"blogs_mysql_mysql笔记11-锁.md\":\"CSRUoguF\",\"blogs_mysql_mysql笔记12-用户管理.md\":\"DfacYyL0\",\"blogs_mysql_mysql笔记13-优化.md\":\"CSuVe00Q\",\"blogs_mysql_mysql笔记14-mvcc.md\":\"BJjOzH-o\",\"blogs_mysql_mysql笔记15-底层.md\":\"DqpmrwbL\",\"blogs_mysql_mysql笔记2.md\":\"JXB94rPt\",\"blogs_mysql_mysql笔记3-表的结构.md\":\"Dm9Fbots\",\"blogs_mysql_mysql笔记4-表中数据.md\":\"BWyymjzt\",\"blogs_mysql_mysql笔记5-约束.md\":\"BdzdI1Uv\",\"blogs_mysql_mysql笔记6-视图.md\":\"aJpfSbvO\",\"blogs_mysql_mysql笔记7-索引.md\":\"CekiTF_l\",\"blogs_mysql_mysql笔记8-存储过程和存储函数.md\":\"CPvksjbJ\",\"blogs_mysql_mysql笔记9-触发器.md\":\"CIEw2akL\",\"blogs_nacos_微服务注册与配置中心nacos.md\":\"DjycgaNB\",\"blogs_nas_raid介绍.md\":\"CqjcBFB1\",\"blogs_nas_unraid笔记1-介绍与安装.md\":\"q3k_6jdJ\",\"blogs_nas_unraid笔记2-系统配置.md\":\"Cl5gDLu7\",\"blogs_nas_unraid笔记3-应用.md\":\"gFm1OrZo\",\"blogs_nas_unraid笔记4-硬盘存储设备.md\":\"BSYZN9o-\",\"blogs_nas_unraid笔记5-共享文件夹.md\":\"DFcq8Buk\",\"blogs_nas_unraid笔记6-迁移数据.md\":\"Qs2YUend\",\"blogs_nas_unraid笔记7-虚拟机.md\":\"olbCIRvU\",\"blogs_nas_unraid笔记8-问题.md\":\"CNqJo2GI\",\"blogs_nas_win11_nas笔记.md\":\"8TkS7-QV\",\"blogs_nas_我的nas.md\":\"BUmeiUDr\",\"blogs_nas_硬盘smart信息.md\":\"BLDhuhqx\",\"blogs_nas_群晖docker安装jellyfin媒体库.md\":\"Cj7U976H\",\"blogs_nas_群晖docker安装青龙面板.md\":\"BxoMqqcu\",\"blogs_nas_黑群晖j1900主板.md\":\"Cy4arVF0\",\"blogs_nginx_nginx.md\":\"lgx0SqZG\",\"blogs_nginx_nginx多配置文件.md\":\"DsWLozPx\",\"blogs_nginx_nginx容器笔记.md\":\"C1fZam--\",\"blogs_nginx_nginx负载均衡配置.md\":\"4Yg7z9sT\",\"blogs_nginx_nginx配置文件的斜线问题.md\":\"DpzpVB41\",\"blogs_nodejs_nodejs.md\":\"CWhW46_d\",\"blogs_nodejs_nodemon笔记.md\":\"B69NdM7L\",\"blogs_nodejs_nvm的使用.md\":\"DMzsAg1S\",\"blogs_nodejs_pnpm笔记.md\":\"u5_c6KKH\",\"blogs_nuxtjs_nuxtjs笔记1.md\":\"mbuHMFYk\",\"blogs_openfeign_微服务接口调用组件openfeign.md\":\"DqGQ11vv\",\"blogs_python_python使用beautifulsoup4库笔记.md\":\"C9qay77e\",\"blogs_python_python使用ddddocr验证码识别库.md\":\"DcXh22Ae\",\"blogs_python_python使用dlib机器学习库笔记.md\":\"Cl9muDfV\",\"blogs_python_python使用loguru日志库笔记.md\":\"DJs9td1m\",\"blogs_python_python使用ocr工具库pytesseract笔记.md\":\"98LthO3W\",\"blogs_python_python使用opencv-python库笔记.md\":\"CmaCjBO6\",\"blogs_python_python使用openpyxl库笔记.md\":\"basA9t87\",\"blogs_python_python使用oss2库笔记.md\":\"CCRva7YD\",\"blogs_python_python使用pdfplumber库笔记.md\":\"Cv0U_icy\",\"blogs_python_python使用pycryptodome库笔记.md\":\"9lTWI9pV\",\"blogs_python_python使用pyinstaller库笔记.md\":\"DUPLlE_q\",\"blogs_python_python使用pyside6库笔记.md\":\"JM-998it\",\"blogs_python_python使用redis-py库笔记.md\":\"0F_nPUJl\",\"blogs_python_python使用requests库笔记.md\":\"CwcsRW2A\",\"blogs_python_python使用scapy库笔记.md\":\"D_KCDTnH\",\"blogs_python_python使用selenium库笔记.md\":\"x6CJ03Ck\",\"blogs_python_python使用sqlite3库笔记.md\":\"0iOjF5yx\",\"blogs_python_python使用tinydb库笔记.md\":\"DAKtXA5D\",\"blogs_python_python使用ua笔记.md\":\"1X1HLLp1\",\"blogs_python_python的drissionpage网页自动化工具库笔记.md\":\"CpQ8y-01\",\"blogs_python_python的pandas数据分析库笔记.md\":\"JuXI7hvz\",\"blogs_python_python笔记1.md\":\"9MUffuHf\",\"blogs_python_python笔记2.md\":\"CcEg2e46\",\"blogs_python_python笔记3.md\":\"7pyjbQpv\",\"blogs_python_python笔记4.md\":\"xQtbc3ED\",\"blogs_python_python笔记5.md\":\"0EHyYsC9\",\"blogs_python_python虚拟环境笔记.md\":\"CDFgjZr5\",\"blogs_python_python调用js代码笔记.md\":\"CkYE-aQ8\",\"blogs_redis_redisson笔记1.md\":\"D1xqNQ-0\",\"blogs_redis_redis笔记1.md\":\"BluUIxEL\",\"blogs_redis_redis笔记2.md\":\"grYk6tRp\",\"blogs_redis_redis笔记3.md\":\"BPCsFM01\",\"blogs_redis_redis笔记4.md\":\"BbqHazuF\",\"blogs_redis_redis笔记5.md\":\"OtpZQ5KE\",\"blogs_redis_springboot整合redis.md\":\"DuMqmkmI\",\"blogs_redis_如何保障redis和mysql的数据一致性.md\":\"CU2BS_4A\",\"blogs_ribbon_微服务负载均衡器ribbon.md\":\"DIsdgquk\",\"blogs_rocketmq_rocketmq笔记1.md\":\"oUyrsZty\",\"blogs_rocketmq_rocketmq笔记2.md\":\"Di3YLbdq\",\"blogs_rocketmq_rocketmq笔记3.md\":\"7P_j2WJN\",\"blogs_seata_微服务分布式事务组件seata.md\":\"BfA8witk\",\"blogs_sentinel_微服务流量控制组件sentinel.md\":\"DQAQGjNi\",\"blogs_shiro_shiro.md\":\"BdfagMHM\",\"blogs_skywalking_微服务链路追踪组件skywalking.md\":\"CygmN8tg\",\"blogs_spring_spring笔记1-介绍.md\":\"B53SZlwu\",\"blogs_spring_spring笔记2-控制反转和依赖注入.md\":\"B0gCEMxv\",\"blogs_spring_spring笔记3-注解.md\":\"rldiatCp\",\"blogs_spring_spring笔记4-aop.md\":\"qri3EWm6\",\"blogs_spring_spring笔记5-事务.md\":\"BWhX8yXQ\",\"blogs_springboot_springboot笔记1.md\":\"wrzblmLz\",\"blogs_springboot_springboot笔记2.md\":\"BJmTM6DB\",\"blogs_springboot_可执行jar包和普通jar包的区别.md\":\"BpV9jhkK\",\"blogs_springcloud_springcloud笔记1.md\":\"CU_RfhyK\",\"blogs_springcloudalibaba_springcloudalibaba笔记.md\":\"b3ktNsBX\",\"blogs_springcloudgateway_微服务网关组件springcloudgateway笔记1.md\":\"CG-7w9wq\",\"blogs_springcloudgateway_微服务网关组件springcloudgateway笔记2.md\":\"DtFbnAUJ\",\"blogs_springdata_springdata笔记.md\":\"BQzLQNvI\",\"blogs_springdatajpa_springdatajpa.md\":\"Dvgk6bWS\",\"blogs_springdatajpa_springdatajpa笔记.md\":\"BfRFWsmJ\",\"blogs_springmvc_springmvc笔记1.md\":\"Dd0cqXeM\",\"blogs_springmvc_springmvc笔记2.md\":\"B38Y3FKz\",\"blogs_springmvc_springmvc笔记3.md\":\"g-P0JpyK\",\"blogs_springsecurity_springsecurity笔记1.md\":\"mBkz8s_6\",\"blogs_sqlalchemy_sqlalchemy笔记1.md\":\"CxjwcS6n\",\"blogs_sqlite_sqlite笔记1.md\":\"Bgf1xnTa\",\"blogs_squid_squid笔记.md\":\"M78u9G5R\",\"blogs_svn_svn笔记.md\":\"DoAnaFWA\",\"blogs_swagger_swagger接口文档.md\":\"CF3NLNha\",\"blogs_tomcat_tomcat.md\":\"7UKgYcLR\",\"blogs_typescript_typescript笔记1.md\":\"CrBKaHBI\",\"blogs_typescript_typescript笔记2.md\":\"C4XkO2sI\",\"blogs_vitepress_vitepress笔记1.md\":\"DSwN-l7q\",\"blogs_vitepress_vitepress笔记2.md\":\"B6qAEqcA\",\"blogs_vue_pinia笔记.md\":\"BMBuXQsb\",\"blogs_vue_vitepluginmock使用笔记.md\":\"CDa9MVSx\",\"blogs_vue_vue-cli3脚手架打包不同环境的项目.md\":\"LTw8aSjU\",\"blogs_vue_vue-cli脚手架项目使用自定义组件.md\":\"DoHQRt6D\",\"blogs_vue_vue.js.md\":\"B8BuGVwm\",\"blogs_vue_vue3动态路由刷新问题.md\":\"DfRDOH3l\",\"blogs_vue_vue3笔记.md\":\"DWMKD4GX\",\"blogs_vue_vuerouter.md\":\"CNHHo-TT\",\"blogs_vue_vuex.md\":\"wKruejQ2\",\"blogs_vue_vue加载高德地图.md\":\"YYZ61TgI\",\"blogs_vue_vue工程部署的各种情况与问题.md\":\"DmZsv3km\",\"blogs_vue_vue常用js库.md\":\"CFM2NDSt\",\"blogs_vue_vue父与子组件通信和互相调用的方法.md\":\"Djvu_Fe0\",\"blogs_vue_vue随笔1.md\":\"DK4A6Huw\",\"blogs_vue_vue随笔2.md\":\"Cj9cXPTe\",\"blogs_vuepress_vuepress博客优化.md\":\"IEBnhwKT\",\"blogs_windows_windows.md\":\"5H9L4DEy\",\"blogs_windows_windows系统下开发环境启动脚本.md\":\"DgjXMWld\",\"blogs_xxljob_xxl-job笔记1.md\":\"_XYqccWh\",\"blogs_xxljob_xxl-job笔记2.md\":\"B_OKj1Q9\",\"blogs_个人项目_java实体类与表设计.md\":\"ChJmmpkz\",\"blogs_个人项目_shuyx-admin-ui项目笔记.md\":\"DWR6TwnS\",\"blogs_个人项目_shuyxwebsite笔记.md\":\"C9u1uIhN\",\"blogs_个人项目_关于我.md\":\"CI_ty1w-\",\"blogs_个人项目_管理后台的前端解决方案.md\":\"BxYtmVzu\",\"blogs_内网穿透_zerotier内网穿透.md\":\"D3OLKTyA\",\"blogs_开发_bootstrap和application配置文件.md\":\"DVdesEnS\",\"blogs_开发_springboot整合redis.md\":\"C_4VtzaD\",\"blogs_开发_springboot整合日志.md\":\"DonEhswg\",\"blogs_开发_springboot配置自定义拦截器.md\":\"Cf_d41aF\",\"blogs_开发_vue3工程的搭建细节.md\":\"Bk_6cD_T\",\"blogs_开发_后台代码四层架构的作用.md\":\"DXSmhNsh\",\"blogs_开发_开发规范.md\":\"BivOjER9\",\"blogs_开发_用户认证方案.md\":\"Cevcu-Wk\",\"blogs_开发_自定义异常和统一结果返回对象.md\":\"COUVSxi7\",\"blogs_数据结构和算法_pat乙级(1).md\":\"D-ovZYCf\",\"blogs_数据结构和算法_数据结构java实现-链表.md\":\"-mffdWgT\",\"blogs_数据结构和算法_数据结构java实现-队列.md\":\"CACisOLy\",\"blogs_数据结构和算法_数据结构基础(1).md\":\"D4USnoFn\",\"blogs_数据结构和算法_算法刷题1.md\":\"DunIfDCH\",\"blogs_服务器_1panel服务器面板笔记.md\":\"tzZCOtG-\",\"blogs_爬虫_java爬虫.md\":\"BgIavv0y\",\"blogs_爬虫_爬虫笔记01.md\":\"C5FGm_sU\",\"blogs_爬虫_爬虫笔记02.md\":\"lr2l764Q\",\"blogs_爬虫_爬虫笔记03.md\":\"2izvZlBZ\",\"blogs_简历_readme.md\":\"DwZ2j2A6\",\"blogs_英语_长难句解析(1).md\":\"AYAMgrXF\",\"blogs_计算机网络_计算机网络笔记01.md\":\"Dy9kfA7C\",\"blogs_设计模式_设计模式笔记1.md\":\"Bv12Tfe8\",\"blogs_软考_软件设计师笔记01_计算机系统知识概述.md\":\"CVjM1j69\",\"blogs_软考_软件设计师笔记02_程序设计语言基础.md\":\"CDRNHEy-\",\"blogs_软考_软件设计师笔记03_数据结构与数据运算.md\":\"CEmgYWu5\",\"blogs_软考_软件设计师笔记04_操作系统知识.md\":\"Be-dv50O\",\"blogs_软考_软件设计师笔记05_软件工程基础.md\":\"EDK0TU-h\",\"blogs_软考_软件设计师笔记06_结构化开发方法.md\":\"BcAViQRU\",\"blogs_软考_软件设计师笔记07_面向对象技术.md\":\"BXr6fvlc\",\"blogs_软考_软件设计师笔记08_算法设计与分析.md\":\"xUx-A5pu\",\"blogs_软考_软件设计师笔记09_数据库技术基础.md\":\"DT62SsKH\",\"blogs_软考_软件设计师笔记10_网络与信息安全基础知识.md\":\"uZogRnix\",\"blogs_软考_软件设计师笔记11_标准化和软件知识产权基础知识.md\":\"C7q3W09R\",\"blogs_软考_软件设计师笔记12_软件系统分析与设计.md\":\"d247WEWm\",\"blogs_软考_软件设计师笔记13_新技术.md\":\"3s4LnJNW\",\"blogs_软考_软件设计师笔记_应用大题_精简考点.md\":\"BhyyhxY6\",\"blogs_软考_软件设计师笔记_第一章_计算机系统组成_精简考点.md\":\"Deu7EpKk\",\"blogs_软考_软件设计师笔记_第七章_面向对象_精简考点.md\":\"DUNod8IW\",\"blogs_软考_软件设计师笔记_第九章_数据库系统_精简考点.md\":\"vOwFS6BM\",\"blogs_软考_软件设计师笔记_第二章_程序语言设计_考点.md\":\"xAKLvBjo\",\"blogs_软考_软件设计师笔记_第五章_软件工程_精简考点.md\":\"BW-0pjYV\",\"blogs_软考_软件设计师笔记_第八章_数据结构与算法_精简考点.md\":\"Btamv0fV\",\"blogs_软考_软件设计师笔记_第六章_结构化开发_精简考点.md\":\"CNREhe7H\",\"blogs_软考_软件设计师笔记_第十一章_知识产权_精简考点.md\":\"D-R2W1aL\",\"blogs_软考_软件设计师笔记_第十章_网络安全_精简考点.md\":\"qcUpI4f-\",\"blogs_软考_软件设计师笔记_第四章_操作系统_精简考点.md\":\"CZgCN-iT\",\"blogs_软路由_ipv6笔记.md\":\"DNhTyKEo\",\"blogs_软路由_openwrt设置.md\":\"BryhY5IN\",\"blogs_软路由_小米路由器4a千兆版刷机.md\":\"CgLvk3dA\",\"blogs_软路由_软路由介绍.md\":\"BVJD6X3I\",\"blogs_阅读笔记_《囚徒健身》笔记.md\":\"C3GSC-No\",\"blogs_阅读笔记_《英语词根和单词的说文解字》笔记.md\":\"RvV2WYyj\",\"blogs_阅读笔记_《软技能-代码之外的生存指南》笔记.md\":\"BfWoYeo5\",\"blogs_随笔_apachepoi对办公文档的操作.md\":\"B_k_Q8Io\",\"blogs_随笔_elementplus的进度条使用.md\":\"BkXgpgmy\",\"blogs_随笔_ffmpeg的使用.md\":\"COC5B4z4\",\"blogs_随笔_file类读取resources目录文件.md\":\"B2O-yAuh\",\"blogs_随笔_get请求参数包含中括号__时报错.md\":\"DZnkzvua\",\"blogs_随笔_github网站无法访问.md\":\"NTbkgpUl\",\"blogs_随笔_github自动提交代码脚本.md\":\"C_Wt5W1e\",\"blogs_随笔_http请求笔记.md\":\"BONeV_a4\",\"blogs_随笔_iptable与netfilter笔记.md\":\"KHMVgZHH\",\"blogs_随笔_java与mysql中的时间类型对应.md\":\"DmZpoWEQ\",\"blogs_随笔_java实体类为什么要序列化.md\":\"D_4CVq8M\",\"blogs_随笔_java运行脚本.md\":\"Ch1-mElw\",\"blogs_随笔_java随笔1.md\":\"CeH_gN66\",\"blogs_随笔_laas和paas和saas等aas是什么.md\":\"DDa8q-iw\",\"blogs_随笔_lombok的使用.md\":\"C2JWXr5m\",\"blogs_随笔_mobaxterm终端工具笔记.md\":\"CrJzozgP\",\"blogs_随笔_nginx随笔1.md\":\"Da-85YlF\",\"blogs_随笔_redis修改密码.md\":\"CBhCBjtC\",\"blogs_随笔_restful风格.md\":\"DnvoEHR6\",\"blogs_随笔_springboot随笔1.md\":\"e9e1gfaO\",\"blogs_随笔_ssl证书.md\":\"r51VrD3-\",\"blogs_随笔_vscode导包报错.md\":\"DWtKHw3r\",\"blogs_随笔_wechatapp.md\":\"C_HRz25m\",\"blogs_随笔_windows10企业版ltsc2019最新激活方法.md\":\"CbBGcaVo\",\"blogs_随笔_windows下把ssl证书导入jdk的cacerts证书库.md\":\"DP4ihHkl\",\"blogs_随笔_window系统读取群晖的拆机硬盘.md\":\"oabO4yMs\",\"blogs_随笔_下载的zip文件出现损坏的问题.md\":\"BY4gfBbQ\",\"blogs_随笔_健身笔记.md\":\"B5565C62\",\"blogs_随笔_内外网同时访问.md\":\"Ds1BeUCT\",\"blogs_随笔_分销系统1.md\":\"x0wUuIUh\",\"blogs_随笔_华硕x205ta思聪本重装系统.md\":\"CgBnrn6v\",\"blogs_随笔_图片防盗链.md\":\"D_eVwv8C\",\"blogs_随笔_在微信小程序中修改uni-ui组件样式不生效的解决方案.md\":\"DEVmIYCQ\",\"blogs_随笔_多租户系统.md\":\"CSQDmajT\",\"blogs_随笔_已连接wifi但无法上网问题.md\":\"CCZJfitM\",\"blogs_随笔_常见的数据存储方式.md\":\"DxRuEjQV\",\"blogs_随笔_常见的文件共享协议.md\":\"DiNC1s8V\",\"blogs_随笔_微信内置浏览器-f12调试工具.md\":\"DVaxaGxz\",\"blogs_随笔_微信小程序https访问.md\":\"D3v8FZA8\",\"blogs_随笔_微信小程序封装请求api.js并封装token.md\":\"DZquC1xr\",\"blogs_随笔_微服务概述及常见解决方案.md\":\"CffJymii\",\"blogs_随笔_搜索引擎高级用法.md\":\"ugPnb8Gm\",\"blogs_随笔_正则表达式.md\":\"BU3oqkSk\",\"blogs_随笔_浏览器工作原理.md\":\"BjKJTF12\",\"blogs_随笔_浏览器的err_unsafe_port问题.md\":\"CLhjn-GU\",\"blogs_随笔_神舟战神k670d刷bios.md\":\"DpVPsKeY\",\"blogs_随笔_离职该怎么做？.md\":\"C3Nvtd6K\",\"blogs_随笔_科目一笔记.md\":\"CHMbkFvK\",\"blogs_随笔_科目三笔记.md\":\"DvSYGGOT\",\"blogs_随笔_科目二笔记.md\":\"BYweMQam\",\"blogs_随笔_系统服务架构的演变.md\":\"BBfuawBc\",\"blogs_随笔_购车指南.md\":\"CwbNm0wg\",\"blogs_随笔_配眼镜笔记.md\":\"DuF3V3Sp\",\"blogs_随笔_重装开发环境.md\":\"CCTxtCUb\",\"blogs_面试_java面试题总结-javaweb.md\":\"CjX2_JLe\",\"blogs_面试_java面试题总结-jvm.md\":\"DCFFIV8f\",\"blogs_面试_java面试题总结-事务1.md\":\"CpndCHxo\",\"blogs_面试_java面试题总结-基础1.md\":\"CiRWSk0i\",\"blogs_面试_java面试题总结-线程1.md\":\"BT0O0B5B\",\"blogs_面试_java面试题总结-设计模式.md\":\"CxIFN_kO\",\"blogs_面试_java面试题总结-锁1.md\":\"BpfM_k0W\",\"blogs_面试_java面试题总结-集合1.md\":\"BTDyskvU\",\"blogs_面试_linux面试题总结.md\":\"EnOq14FN\",\"blogs_面试_mq面试题总结.md\":\"DsWVxgWw\",\"blogs_面试_mybatis面试题总结.md\":\"B8vn25cO\",\"blogs_面试_mysql笔试题总结1.md\":\"CAEtMMWM\",\"blogs_面试_mysql面试题总结1.md\":\"BpNpbvSI\",\"blogs_面试_mysql面试题总结2.md\":\"Hv1SZCRG\",\"blogs_面试_nacos面试题总结.md\":\"Bfad_UV7\",\"blogs_面试_nginx面试题总结.md\":\"CLOO3JSl\",\"blogs_面试_readme.md\":\"DMI44ySF\",\"blogs_面试_redis面试题总结1.md\":\"D7f-AVvR\",\"blogs_面试_ribbon面试题总结.md\":\"G3NDuWdC\",\"blogs_面试_seata面试题总结.md\":\"DYfz-LFd\",\"blogs_面试_sentinal面试题总结.md\":\"DBHFSSYg\",\"blogs_面试_springboot面试题总结.md\":\"BjfS1pVa\",\"blogs_面试_springcloudgateway面试题总结.md\":\"wxBuH3LR\",\"blogs_面试_springcloud面试题总结.md\":\"D53qH8Y6\",\"blogs_面试_springmvc面试题总结.md\":\"B_W2pHKH\",\"blogs_面试_spring面试题总结1.md\":\"DfqZfGtd\",\"blogs_面试_什么是应用程序上下文.md\":\"DzMZhKZt\",\"blogs_面试_微服务面试题总结.md\":\"CkhP0H-Q\",\"blogs_面试_消息队列面试题总结.md\":\"DKJg23lS\",\"blogs_面试_计算机网络面试题总结.md\":\"DdyZBhRm\",\"blogs_面试_项目经验面试题总结.md\":\"BC3nGiCx\",\"index.md\":\"Bwufwcu-\",\"pages_views_archives.md\":\"BEgrOkJ3\",\"pages_views_articlecategory.md\":\"CgDH0WB2\",\"pages_views_articletag.md\":\"BRPAmEuv\",\"pages_views_commentview.md\":\"CBKvuATJ\",\"pages_views_navigationwebsite.md\":\"BBOzCEmG\",\"readme.md\":\"B2Xr7TYg\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"Shuyx Blog\",\"description\":\"Shuyx Blog 是一个基于 VuePress 的静态博客网站。\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"🏠️ 首页\",\"link\":\"/\"},{\"text\":\"🗂️ 分类\",\"link\":\"/pages/views/ArticleCategory.md\"},{\"text\":\"🏷️ 标签\",\"link\":\"/pages/views/ArticleTag.md\"},{\"text\":\"📑 归档\",\"link\":\"/pages/views/Archives.md\"},{\"text\":\"🧭 导航\",\"link\":\"/pages/views/NavigationWebsite.md\"},{\"text\":\"🧑🏻‍💻 面试\",\"link\":\"/blogs/面试/README.md\"},{\"text\":\"🦜 留言板\",\"link\":\"/pages/views/CommentView.md\"},{\"text\":\"🍉 关于\",\"items\":[{\"text\":\"关于我\",\"link\":\"/blogs/个人项目/关于我.md\"},{\"text\":\"Github\",\"link\":\"https://github.com/suichentree\"},{\"text\":\"Gitee\",\"link\":\"https://gitee.com/suichentree\"},{\"text\":\"微信\",\"link\":\"https://weixin.qq.com/\"},{\"text\":\"掘金\",\"link\":\"https://juejin.cn/user/xxxxxx\"},{\"text\":\"CSDN\",\"link\":\"https://blog.csdn.net/xxxx\"}]}],\"logo\":\"/logo.png\",\"siteTitle\":\"Shuyx Blog\",\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/suichentree\"},{\"icon\":{\"svg\":\"<svg t=\\\"1721906075888\\\" class=\\\"icon\\\" viewBox=\\\"0 0 1024 1024\\\" version=\\\"1.1\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\" p-id=\\\"2472\\\" width=\\\"256\\\" height=\\\"256\\\"><path d=\\\"M512 0C230.4 0 0 230.4 0 512s230.4 512 512 512 512-230.4 512-512S793.6 0 512 0z m284.8 313.6c0 12.8-12.8 25.6-25.6 25.6H416c-41.6 0-76.8 35.2-76.8 76.8v243.2c0 12.8 12.8 25.6 25.6 25.6h240c41.6 0 76.8-35.2 76.8-76.8v-12.8c0-12.8-12.8-25.6-25.6-25.6H480c-12.8 0-25.6-12.8-25.6-25.6v-64c0-12.8 12.8-25.6 25.6-25.6h291.2c12.8 0 25.6 12.8 25.6 25.6v144c0 92.8-76.8 169.6-169.6 169.6H252.8c-12.8 0-25.6-12.8-25.6-25.6V412.8C227.2 310.4 310.4 224 416 224h355.2c12.8 0 25.6 12.8 25.6 25.6v64z\\\" fill=\\\"#B32225\\\" p-id=\\\"2473\\\"></path></svg>\"},\"link\":\"https://gitee.com/suichenTree\"}],\"darkModeSwitchLabel\":\"日夜模式\",\"search\":{\"provider\":\"local\",\"options\":{\"translations\":{\"button\":{\"buttonText\":\"搜索文档\",\"buttonAriaLabel\":\"搜索文档\"},\"modal\":{\"noResultsText\":\"无法找到相关结果\",\"displayDetails\":\"显示详情\",\"resetButtonTitle\":\"清除查询条件\",\"footer\":{\"selectText\":\"选择\",\"navigateText\":\"切换\",\"closeText\":\"关闭\"}}}}},\"footer\":{\"message\":\"Released under the MIT License.\",\"copyright\":\"Copyright © 2017-2025 present shuyx\"},\"outline\":{\"level\":[1,6],\"label\":\"文章大纲目录\"},\"sidebar\":{\"/blogs/面试/\":[{\"text\":\"面试总结\",\"items\":[{\"text\":\"README\",\"link\":\"/blogs/面试/README.md\"},{\"text\":\"Java面试题\",\"collapsed\":false,\"items\":[{\"text\":\"项目经验面试题总结\",\"link\":\"/blogs/面试/项目经验面试题总结.md\"},{\"text\":\"什么是应用程序上下文\",\"link\":\"/blogs/面试/什么是应用程序上下文.md\"},{\"text\":\"Java面试题总结-基础1\",\"link\":\"/blogs/面试/Java面试题总结-基础1.md\"},{\"text\":\"Java面试题总结-集合1\",\"link\":\"/blogs/面试/Java面试题总结-集合1.md\"},{\"text\":\"Java面试题总结-设计模式\",\"link\":\"/blogs/面试/Java面试题总结-设计模式.md\"},{\"text\":\"Java面试题总结-事务1\",\"link\":\"/blogs/面试/Java面试题总结-事务1.md\"},{\"text\":\"Java面试题总结-锁1\",\"link\":\"/blogs/面试/Java面试题总结-锁1.md\"},{\"text\":\"Java面试题总结-线程1\",\"link\":\"/blogs/面试/Java面试题总结-线程1.md\"},{\"text\":\"Java面试题总结-JavaWeb\",\"link\":\"/blogs/面试/Java面试题总结-JavaWeb.md\"},{\"text\":\"Java面试题总结-JVM\",\"link\":\"/blogs/面试/Java面试题总结-JVM.md\"}]},{\"text\":\"MySql面试题\",\"collapsed\":false,\"items\":[{\"text\":\"MySql笔试题总结1\",\"link\":\"/blogs/面试/MySql笔试题总结1.md\"},{\"text\":\"MySql面试题总结1\",\"link\":\"/blogs/面试/MySql面试题总结1.md\"},{\"text\":\"MySql面试题总结2\",\"link\":\"/blogs/面试/MySql面试题总结2.md\"}]},{\"text\":\"Redis面试题\",\"collapsed\":false,\"items\":[{\"text\":\"Redis面试题总结1\",\"link\":\"/blogs/面试/Redis面试题总结1.md\"}]},{\"text\":\"Mybatis面试题\",\"collapsed\":false,\"items\":[{\"text\":\"Mybatis面试题总结\",\"link\":\"/blogs/面试/Mybatis面试题总结.md\"}]},{\"text\":\"Spring面试题\",\"collapsed\":false,\"items\":[{\"text\":\"Spring面试题总结1\",\"link\":\"/blogs/面试/Spring面试题总结1.md\"},{\"text\":\"SpringMVC面试题总结\",\"link\":\"/blogs/面试/SpringMVC面试题总结.md\"},{\"text\":\"SpringBoot面试题总结\",\"link\":\"/blogs/面试/SpringBoot面试题总结.md\"},{\"text\":\"SpringCloud面试题总结\",\"link\":\"/blogs/面试/SpringCloud面试题总结.md\"},{\"text\":\"SpringCloudGateway面试题总结\",\"link\":\"/blogs/面试/SpringCloudGateway面试题总结.md\"}]},{\"text\":\"微服务面试题\",\"collapsed\":false,\"items\":[{\"text\":\"微服务面试题总结\",\"link\":\"/blogs/面试/微服务面试题总结.md\"},{\"text\":\"消息队列面试题总结\",\"link\":\"/blogs/面试/消息队列面试题总结.md\"},{\"text\":\"MQ面试题总结\",\"link\":\"/blogs/面试/MQ面试题总结.md\"},{\"text\":\"Ribbon面试题总结\",\"link\":\"/blogs/面试/Ribbon面试题总结.md\"},{\"text\":\"Seata面试题总结\",\"link\":\"/blogs/面试/Seata面试题总结.md\"},{\"text\":\"Sentinal面试题总结\",\"link\":\"/blogs/面试/Sentinal面试题总结.md\"}]}]}]},\"sidebarMenuLabel\":\"侧边栏\",\"notFound\":{\"title\":\"未找到页面，迷路了~\",\"quote\":\"请检查地址是否正确，或当前页面未开通，点击下方按钮返回首页\",\"linkText\":\"返回首页\"},\"markdown\":{\"image\":{\"lazyLoading\":true,\"lineNumbers\":true}}},\"locales\":{\"root\":{\"label\":\"简体中文\",\"lang\":\"Zh_CN\"},\"en\":{\"label\":\"English\",\"lang\":\"en\",\"link\":\"/en/\"}},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>